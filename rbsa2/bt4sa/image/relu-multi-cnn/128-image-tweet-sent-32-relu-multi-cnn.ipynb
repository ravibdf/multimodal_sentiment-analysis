{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umln0h6MLQqD",
    "tags": []
   },
   "source": [
    "# Importando as bibliotecas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rbsa2\\AppData\\Local\\Temp\\ipykernel_18444\\2828644452.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8680792739478492068\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2252026676\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2492814721059881620\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "type(gpus)\n",
    "if gpus:\n",
    "  # Replicate your computation on multiple GPUs\n",
    "  c = []\n",
    "  for gpu in gpus:\n",
    "    with tf.device(gpu.name):\n",
    "        print(gpu.name)\n",
    "        pass\n",
    "gpu = gpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('./')\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import Convolution1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import ThresholdedReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import models\n",
    "import h5py\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import Input\n",
    "from tensorflow.keras import optimizers\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "import sklearn.metrics as sklm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KSRqGGEH2_Ny"
   },
   "outputs": [],
   "source": [
    "CHARNN_DATA_CONFIG = \"D:/SiDi/Project/Modulo II/github/multimodal-sentiment-analysis/rbsa2/charnn_cnn/charcnn_data_config.json\"\n",
    "charcnn_data_config = pd.read_json(CHARNN_DATA_CONFIG)\n",
    "\n",
    "CNN_DATA_CONFIG = \"D:/SiDi/Project/Modulo II/github/multimodal-sentiment-analysis/rbsa2/charnn_cnn/nn_config.json\"\n",
    "nn_data_config = pd.read_json(CNN_DATA_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "94AqsbHfVdB1"
   },
   "outputs": [],
   "source": [
    "#data_config = json.load(open(\"charcnn_data_config.json\")) #Leitura do arquivo de configuracao\n",
    "data_config = charcnn_data_config #Leitura do arquivo de configuracao\n",
    "\n",
    "#nn_config = json.load(open(\"nn_config.json\")) # Leitura de arquivo de configuracao, quais sao os parametros\n",
    "nn_config = nn_data_config # Leitura de arquivo de configuracao, quais sao os parametros\n",
    "\n",
    "alphabet_size = data_config[\"data\"][\"alphabet_size\"]+1 #tamanho do alfabeto\n",
    "input_size = data_config[\"data\"][\"input_size\"] #Tamanho do input de zi\n",
    "\n",
    "fully_connected_layers = nn_config[\"char_cnn_zhang\"][\"fully_connected_layers\"] #Camadas Conectadas\n",
    "conv_layers = nn_config[\"char_cnn_zhang\"][\"conv_layers\"] #Camadas Convulacionasi\n",
    "threshold = nn_config[\"char_cnn_zhang\"][\"threshold\"] # Limiar\n",
    "dropout_p = nn_config[\"char_cnn_zhang\"][\"dropout_p\"] #Taxa de Dropout\n",
    "embedding_size = nn_config[\"char_cnn_zhang\"][\"embedding_size\"] # Tamnho do Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uFSgTy5kVdB2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH_URL  = \"D:/SiDi/Project/Modulo II/dataset/dataset_sidi_512.csv\"\n",
    "df = pd.read_csv(DATASET_PATH_URL, sep='\\t')\n",
    "\n",
    "print(len(df))\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>382583</td>\n",
       "      <td>382583</td>\n",
       "      <td>798338609870872577-2</td>\n",
       "      <td>0.774375</td>\n",
       "      <td>0.174701</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>what does it look like i do for a living? (cra...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79833/798338609870872577-2.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>443004</td>\n",
       "      <td>443004</td>\n",
       "      <td>802556641057054721-1</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.304103</td>\n",
       "      <td>0.155888</td>\n",
       "      <td>No cheat just skill. #ClikerHeroes https://t.c...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80255/802556641057054721-1.jpg</td>\n",
       "      <td>707</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>348885</td>\n",
       "      <td>348885</td>\n",
       "      <td>796032212407721984-1</td>\n",
       "      <td>0.513661</td>\n",
       "      <td>0.322456</td>\n",
       "      <td>0.163883</td>\n",
       "      <td>@KEILOin_DaTrunk I deleted https://t.co/qIhBkn...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79603/796032212407721984-1.jpg</td>\n",
       "      <td>1334</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>377487</td>\n",
       "      <td>377487</td>\n",
       "      <td>798011160532381696-1</td>\n",
       "      <td>0.712648</td>\n",
       "      <td>0.254173</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>\"RT NYTFashion: How Nasty Gal went from an eBa...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/79801/798011160532381696-1.jpg</td>\n",
       "      <td>561</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>423703</td>\n",
       "      <td>423703</td>\n",
       "      <td>801181521679790080-1</td>\n",
       "      <td>0.713677</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.099468</td>\n",
       "      <td>I hate this nigga lmaooo https://t.co/gPcyJfJESN</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/80118/801181521679790080-1.jpg</td>\n",
       "      <td>1334</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  Unnamed: 0.1            image_name       NEG       NEU  \\\n",
       "0      0      382583        382583  798338609870872577-2  0.774375  0.174701   \n",
       "1      1      443004        443004  802556641057054721-1  0.540009  0.304103   \n",
       "2      2      348885        348885  796032212407721984-1  0.513661  0.322456   \n",
       "3      3      377487        377487  798011160532381696-1  0.712648  0.254173   \n",
       "4      4      423703        423703  801181521679790080-1  0.713677  0.186854   \n",
       "\n",
       "        POS                                               text sent_text  \\\n",
       "0  0.050924  what does it look like i do for a living? (cra...       NEG   \n",
       "1  0.155888  No cheat just skill. #ClikerHeroes https://t.c...       NEG   \n",
       "2  0.163883  @KEILOin_DaTrunk I deleted https://t.co/qIhBkn...       NEG   \n",
       "3  0.033180  \"RT NYTFashion: How Nasty Gal went from an eBa...       NEG   \n",
       "4  0.099468   I hate this nigga lmaooo https://t.co/gPcyJfJESN       NEG   \n",
       "\n",
       "   sent_image                           image_path  image_height  image_width  \n",
       "0           0  data/79833/798338609870872577-2.jpg          1280          722  \n",
       "1           0  data/80255/802556641057054721-1.jpg           707         1366  \n",
       "2           0  data/79603/796032212407721984-1.jpg          1334          750  \n",
       "3           0  data/79801/798011160532381696-1.jpg           561         1000  \n",
       "4           0  data/80118/801181521679790080-1.jpg          1334          750  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_dfcmoTpVdB3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent_image\n",
       "0    0.333333\n",
       "1    0.333333\n",
       "2    0.333333\n",
       "Name: index, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica o balanceamento das classes\n",
    "classes = df.groupby('sent_image')['index'].nunique()/df.shape[0] #Agrupe por index\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eRrHD1w4VdB4"
   },
   "outputs": [],
   "source": [
    "image_height = 128 #Defina o tamanho  da imagem\n",
    "image_width = 128 #Defina a largura da iamge\n",
    "from tensorflow.keras.preprocessing.image import load_img #carrega funcao para carraegar imagem\n",
    "from tensorflow.keras.preprocessing.image import img_to_array #carrega funcao para converter imagem para array\n",
    "from PIL import Image\n",
    "#Funcao que remove quebra de linha\n",
    "def remove_spaces(cell):  \n",
    "    return cell.replace('\\n',' ')\n",
    "#Converte que carrega a image e depois convertte para array\n",
    "def get_array(image_path):\n",
    "    img = load_img(\"D:\\\\SiDi\\\\Project\\\\Modulo II\\\\dataset\\\\512\" + '/' + f\"{image_path}.jpg\", target_size=(image_height, image_width), color_mode='grayscale')\n",
    "\n",
    "    return img_to_array(img)\n",
    "\n",
    "\n",
    "#Mapeaa os tipos de classes existente nos rotulos de predicoes\n",
    "def to_one_hot(y, class_mapping, num_classes):\n",
    "    y_int = y.map(class_mapping)\n",
    "    return to_categorical(y_int, num_classes)\n",
    "\n",
    "#X_text = df['text'].apply(remove_spaces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Numero de classes do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fdL7BAx0VdB5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_classes = df['sent_text'].nunique()\n",
    "#Faz o mapeeamento da classe com o id\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['sent_image']))}\n",
    "class_mapping\n",
    "#y_int = df['sent_text'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = []\n",
    "X_train_image = []\n",
    "y_train = []\n",
    "image_path = []\n",
    "y_total = []\n",
    "img_total = []\n",
    "text_total = []\n",
    "page_total = []\n",
    "doc_total = []\n",
    "target_total = []\n",
    "\n",
    "for i in range(1,len(df[:9600]),1):\n",
    "    X_image = df[i-1:i]['image_name'].apply(get_array)\n",
    "    X_text = df[i-1:i]['text']\n",
    "    y = to_one_hot(df[ i-1:i]['sent_image'], class_mapping, num_classes)\n",
    "    \n",
    "    text_image = pd.concat([X_image, X_text], axis=1)\n",
    "    \n",
    "    image_path.extend( df[i-1:i]['image_path'])\n",
    "    #X_train_text.extend(X_text)\n",
    "    X_train_image.extend(X_image)\n",
    "    y_train.extend(y)\n",
    "    y_total.append(y)\n",
    "    #text_total.append(X_text)\n",
    "    img_total.append(X_image)\n",
    "    page_total.append( df[i-1:i]['image_name'])\n",
    "    doc_total.append( df[i-1:i]['image_name'])\n",
    "    target_total.append( df[i-1:i]['sent_image'])\n",
    "    \n",
    "    \n",
    "    \n",
    "#X_train_text = pd.Series(X_train_text)\n",
    "X_train_image = pd.Series(X_train_image)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9599"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_total)\n",
    "len(text_total)\n",
    "len(img_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = []\n",
    "X_test_image = []\n",
    "y_test = []\n",
    "\n",
    "image_path = []\n",
    "y_total = []\n",
    "img_total = []\n",
    "text_total = []\n",
    "page_total = []\n",
    "doc_total = []\n",
    "target_total = []\n",
    "\n",
    "for i in range(1,len(df[9601:]),1):\n",
    "    X_image = df[i-1:i]['image_name'].apply(get_array)\n",
    "    y = to_one_hot(df[i-1:i]['sent_image'], class_mapping, num_classes)\n",
    "    \n",
    "    #text_image = pd.concat([X_image, X_text], axis=1)\n",
    "    \n",
    "    #X_test_text.extend(X_text)\n",
    "    X_test_image.extend(X_image)\n",
    "    y_test.extend(y)\n",
    "    y_total.append(y)\n",
    "    #text_total.append(X_text)\n",
    "    img_total.append(X_image)\n",
    "    page_total.append(df[i-1:i]['image_name'])\n",
    "    doc_total.append(df[i-1:i]['image_name'])\n",
    "    target_total.append(df[i-1:i]['sent_image'])\n",
    "    \n",
    "    \n",
    "#X_test_text = pd.Series(X_test_text)\n",
    "X_test_image = pd.Series(X_test_image)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hnxQmZqfL8Dx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2398, 2398)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_total), len(img_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oj-rAfeilKpY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IfAjT11aFT0"
   },
   "source": [
    "# Join Train and Test (Test and Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XRxLzx9RNC_J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11997"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_join_image = X_train_image.append(X_test_image)\n",
    "len(X_join_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JsPJ43B9QUP"
   },
   "source": [
    "# Converte de Imagem para Array Numpy - image_to_numpy(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tVUP1aAPVdB9"
   },
   "outputs": [],
   "source": [
    "def image_to_numpy(image_df):\n",
    "    all_images = []\n",
    "    for i in range(len(image_df)):\n",
    "        all_images.append(image_df.iloc[i])  \n",
    "    return np.array(all_images)\n",
    "\n",
    "X_train_image = image_to_numpy(X_train_image)\n",
    "X_test_image = image_to_numpy(X_test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nf2VBXRxD_An"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_join_image = image_to_numpy(X_join_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ijk7PaQB9hTt"
   },
   "source": [
    "# Imprime o Shape do Objeto de Treinamento Convertido Array Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ljs8GVLVVdB9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9599, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssjgpvFe91Wg"
   },
   "source": [
    "# (01) - Conjunto de Dados de Validacao - Declara a Classe ImageValidationCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oW8DDL5zVdB9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 121, 121, 32)      2080      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " encoded_image (Dense)       (None, 256)               33024     \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,771\n",
      "Trainable params: 72,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def predict(model, X_test_image, batch_size=32):\n",
    "    y_predict = np.round(model.predict(X_test_image))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class ImageValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_image,y_test, metric = 'kappa'):\n",
    "        self.X_test_image = X_test_image\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, X_test_image)\n",
    "        #true_labels = [label2Idx[x[1]] for x in self.test_data]\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metric)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)\n",
    "\n",
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(32, (8, 8), activation='relu',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (8, 8), activation='relu',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='relu')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='relu', name='encoded_image')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_image)\n",
    "model_image = Model(image_input, output)\n",
    "model_image.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "model_image.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9599, 128, 128, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9599, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2398, 128, 128, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2398, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "300/300 [==============================] - ETA: 0s - loss: 2.2003 - acc: 0.3962\n",
      "accuracy improvement: 0.7756463719766472 (before: -inf), saving to v0.0.1_image-tweet-sent.h5\n",
      "300/300 [==============================] - 29s 81ms/step - loss: 2.2003 - acc: 0.3962 - val_loss: 0.7896 - val_acc: 0.6493\n",
      "Epoch 2/18\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.1476 - acc: 0.4086\n",
      "accuracy improvement: 0.872393661384487 (before: 0.7756463719766472), saving to v0.0.1_image-tweet-sent.h5\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 1.1476 - acc: 0.4086 - val_loss: 0.7469 - val_acc: 0.7185\n",
      "Epoch 3/18\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.0606 - acc: 0.4307\n",
      "accuracy improvement: 0.9516263552960801 (before: 0.872393661384487), saving to v0.0.1_image-tweet-sent.h5\n",
      "300/300 [==============================] - 23s 77ms/step - loss: 1.0606 - acc: 0.4307 - val_loss: 0.8388 - val_acc: 0.6939\n",
      "Epoch 4/18\n",
      "300/300 [==============================] - 23s 77ms/step - loss: 1.0389 - acc: 0.4351 - val_loss: 0.9606 - val_acc: 0.2477\n",
      "Epoch 5/18\n",
      "300/300 [==============================] - 23s 75ms/step - loss: 1.0298 - acc: 0.4388 - val_loss: 1.0079 - val_acc: 0.1877\n",
      "Epoch 6/18\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.0206 - acc: 0.4523\n",
      "accuracy improvement: 0.9883236030025021 (before: 0.9516263552960801), saving to v0.0.1_image-tweet-sent.h5\n",
      "300/300 [==============================] - 23s 76ms/step - loss: 1.0206 - acc: 0.4523 - val_loss: 0.7798 - val_acc: 0.9028\n",
      "Epoch 7/18\n",
      "300/300 [==============================] - 23s 75ms/step - loss: 1.0151 - acc: 0.4584 - val_loss: 0.8589 - val_acc: 0.4975\n",
      "Epoch 8/18\n",
      "300/300 [==============================] - 22s 75ms/step - loss: 1.0032 - acc: 0.4650 - val_loss: 0.8667 - val_acc: 0.6301\n",
      "Epoch 9/18\n",
      "300/300 [==============================] - 22s 74ms/step - loss: 0.9930 - acc: 0.4799 - val_loss: 0.9256 - val_acc: 0.2723\n",
      "Epoch 10/18\n",
      "300/300 [==============================] - 23s 76ms/step - loss: 0.9854 - acc: 0.4860 - val_loss: 0.8460 - val_acc: 0.5400\n",
      "Epoch 11/18\n",
      "300/300 [==============================] - 23s 76ms/step - loss: 0.9769 - acc: 0.4954 - val_loss: 0.8132 - val_acc: 0.5225\n",
      "Epoch 12/18\n",
      "300/300 [==============================] - 24s 79ms/step - loss: 0.9702 - acc: 0.4947 - val_loss: 0.8519 - val_acc: 0.4608\n",
      "Epoch 13/18\n",
      "300/300 [==============================] - 23s 78ms/step - loss: 0.9590 - acc: 0.5115 - val_loss: 0.9079 - val_acc: 0.4529\n",
      "Epoch 14/18\n",
      "300/300 [==============================] - 24s 80ms/step - loss: 0.9472 - acc: 0.5152 - val_loss: 0.7752 - val_acc: 0.6714\n",
      "Epoch 15/18\n",
      "300/300 [==============================] - 24s 81ms/step - loss: 0.9359 - acc: 0.5230 - val_loss: 0.8183 - val_acc: 0.6134\n",
      "Epoch 16/18\n",
      "300/300 [==============================] - 24s 81ms/step - loss: 0.9264 - acc: 0.5303 - val_loss: 0.8537 - val_acc: 0.4433\n",
      "Epoch 17/18\n",
      "300/300 [==============================] - 25s 84ms/step - loss: 0.9199 - acc: 0.5410 - val_loss: 0.8157 - val_acc: 0.5671\n",
      "Epoch 18/18\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[32,32,15,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model/max_pooling2d_3/MaxPool/MaxPoolGrad\n (defined at D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_992]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model/max_pooling2d_3/MaxPool/MaxPoolGrad:\nIn[0] model/conv2d_3/Relu (defined at D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\backend.py:4867)\t\nIn[1] model/max_pooling2d_3/MaxPool (defined at D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\layers\\pooling.py:357)\t\nIn[2] gradient_tape/model/flatten/Reshape:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Temp\\ipykernel_18444\\4199308014.py\", line 8, in <module>\n>>>     model_image.fit(X_train_image, y_train, epochs=18, batch_size=32,\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_repeats):\n\u001b[0;32m      7\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m ImageValidationCheckpoint(model_file, X_test_image, y_test, metric\u001b[38;5;241m=\u001b[39moptimize_for)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mmodel_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     exp_history\u001b[38;5;241m.\u001b[39mappend(checkpoint\u001b[38;5;241m.\u001b[39mmax_metrics)\n",
      "File \u001b[1;32mD:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,32,15,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/model/max_pooling2d_3/MaxPool/MaxPoolGrad\n (defined at D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_992]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/model/max_pooling2d_3/MaxPool/MaxPoolGrad:\nIn[0] model/conv2d_3/Relu (defined at D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\backend.py:4867)\t\nIn[1] model/max_pooling2d_3/MaxPool (defined at D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\layers\\pooling.py:357)\t\nIn[2] gradient_tape/model/flatten/Reshape:\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\rbsa2\\AppData\\Local\\Temp\\ipykernel_18444\\4199308014.py\", line 8, in <module>\n>>>     model_image.fit(X_train_image, y_train, epochs=18, batch_size=32,\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\engine\\training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> "
     ]
    }
   ],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'accuracy'\n",
    "model_file = 'v0.0.1_image-tweet-sent.h5'\n",
    "with tf.device(gpu.name):\n",
    "    for i in range(n_repeats):\n",
    "        checkpoint = ImageValidationCheckpoint(model_file, X_test_image, y_test, metric=optimize_for)\n",
    "        model_image.fit(X_train_image, y_train, epochs=18, batch_size=32,\n",
    "                         validation_data=(X_test_image, y_test)\n",
    "                         ,callbacks = [checkpoint])\n",
    "        exp_history.append(checkpoint.max_metrics)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_image.save('v0.0.1_32-relu-bt4sa-128-image-tweet-sent.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1711220741271973\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_image.predict(X_test_image)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_class_mapping = {idx:label for idx,label in enumerate(np.unique(df['sent_image']))}\n",
    "id_class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.72      2398\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56      2398\n",
      "   macro avg       0.33      0.19      0.24      2398\n",
      "weighted avg       1.00      0.56      0.72      2398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\qualifacti\\caes-vs-gatos\\caes-vs-gatos\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "\n",
    "pred_class = []\n",
    "for i in range(len(y_pred)):\n",
    "  pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "  pred_class.append(id_class_mapping[pred[0][0]])\n",
    "    \n",
    "print(classification_report(Y_test, pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "0-2-multi-input-nn-hmm-30-mar-2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "caes-vs-gatos",
   "language": "python",
   "name": "caes-vs-gatos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
