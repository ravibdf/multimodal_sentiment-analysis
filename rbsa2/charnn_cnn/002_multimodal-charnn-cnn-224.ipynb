{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umln0h6MLQqD",
    "tags": []
   },
   "source": [
    "# Importando as bibliotecas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rbsa2\\AppData\\Local\\Temp/ipykernel_7588/2828644452.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_built_with_cuda()\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17896301344129938870\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2252026676\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10151996334010579877\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "type(gpus)\n",
    "if gpus:\n",
    "  # Replicate your computation on multiple GPUs\n",
    "  c = []\n",
    "  for gpu in gpus:\n",
    "    with tf.device(gpu.name):\n",
    "        print(gpu.name)\n",
    "        pass\n",
    "gpu = gpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('./')\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import Convolution1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import ThresholdedReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import models\n",
    "import h5py\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import Input\n",
    "from tensorflow.keras import optimizers\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "import sklearn.metrics as sklm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KSRqGGEH2_Ny"
   },
   "outputs": [],
   "source": [
    "CHARNN_DATA_CONFIG = \"D:/SiDi/Project/Modulo II/github/multimodal-sentiment-analysis/rbsa2/charnn_cnn/charcnn_data_config.json\"\n",
    "charcnn_data_config = pd.read_json(CHARNN_DATA_CONFIG)\n",
    "\n",
    "CNN_DATA_CONFIG = \"D:/SiDi/Project/Modulo II/github/multimodal-sentiment-analysis/rbsa2/charnn_cnn/nn_config.json\"\n",
    "nn_data_config = pd.read_json(CNN_DATA_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "94AqsbHfVdB1"
   },
   "outputs": [],
   "source": [
    "#data_config = json.load(open(\"charcnn_data_config.json\")) #Leitura do arquivo de configuracao\n",
    "data_config = charcnn_data_config #Leitura do arquivo de configuracao\n",
    "\n",
    "#nn_config = json.load(open(\"nn_config.json\")) # Leitura de arquivo de configuracao, quais sao os parametros\n",
    "nn_config = nn_data_config # Leitura de arquivo de configuracao, quais sao os parametros\n",
    "\n",
    "alphabet_size = data_config[\"data\"][\"alphabet_size\"]+1 #tamanho do alfabeto\n",
    "input_size = data_config[\"data\"][\"input_size\"] #Tamanho do input de zi\n",
    "\n",
    "fully_connected_layers = nn_config[\"char_cnn_zhang\"][\"fully_connected_layers\"] #Camadas Conectadas\n",
    "conv_layers = nn_config[\"char_cnn_zhang\"][\"conv_layers\"] #Camadas Convulacionasi\n",
    "threshold = nn_config[\"char_cnn_zhang\"][\"threshold\"] # Limiar\n",
    "dropout_p = nn_config[\"char_cnn_zhang\"][\"dropout_p\"] #Taxa de Dropout\n",
    "embedding_size = nn_config[\"char_cnn_zhang\"][\"embedding_size\"] # Tamnho do Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uFSgTy5kVdB2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470586\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH_URL  = \"D:/SiDi/Project/Modulo II/dataset/output/dataset_sidi_v1.2.csv\"\n",
    "df = pd.read_csv(DATASET_PATH_URL, sep='\\t')\n",
    "\n",
    "print(len(df))\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>768097808037605376-1</td>\n",
       "      <td>0.919993</td>\n",
       "      <td>0.055681</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>RT @hoseokahhh: \"who is this song forwhat do i...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097808037605376-1.jpg</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>768097833215938560-1</td>\n",
       "      <td>0.864726</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.076834</td>\n",
       "      <td>RT @ARapperSaid_: “I ain’t come over here for ...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097833215938560-1.jpg</td>\n",
       "      <td>398</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>768097929659817984-1</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-1.jpg</td>\n",
       "      <td>489</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>768097929659817984-2</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-2.jpg</td>\n",
       "      <td>983</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>768097929659817984-3</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-3.jpg</td>\n",
       "      <td>1326</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0            image_name       NEG       NEU       POS  \\\n",
       "0      0           0  768097808037605376-1  0.919993  0.055681  0.024326   \n",
       "1      1           1  768097833215938560-1  0.864726  0.058440  0.076834   \n",
       "2      2           2  768097929659817984-1  0.907574  0.061396  0.031029   \n",
       "3      3           3  768097929659817984-2  0.907574  0.061396  0.031029   \n",
       "4      4           4  768097929659817984-3  0.907574  0.061396  0.031029   \n",
       "\n",
       "                                                text sent_text  sent_image  \\\n",
       "0  RT @hoseokahhh: \"who is this song forwhat do i...       NEG           0   \n",
       "1  RT @ARapperSaid_: “I ain’t come over here for ...       NEG           0   \n",
       "2  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "3  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "4  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "\n",
       "                            image_path  image_height  image_width  \n",
       "0  data/76809/768097808037605376-1.jpg           449          449  \n",
       "1  data/76809/768097833215938560-1.jpg           398          593  \n",
       "2  data/76809/768097929659817984-1.jpg           489         1132  \n",
       "3  data/76809/768097929659817984-2.jpg           983         1123  \n",
       "4  data/76809/768097929659817984-3.jpg          1326         1110  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_dfcmoTpVdB3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent_text\n",
       "NEG    0.333333\n",
       "NEU    0.333333\n",
       "POS    0.333333\n",
       "Name: index, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica o balanceamento das classes\n",
    "classes = df.groupby('sent_text')['index'].nunique()/df.shape[0] #Agrupe por index\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eRrHD1w4VdB4"
   },
   "outputs": [],
   "source": [
    "image_height = 224 #Defina o tamanho  da imagem\n",
    "image_width = 224 #Defina a largura da iamge\n",
    "from tensorflow.keras.preprocessing.image import load_img #carrega funcao para carraegar imagem\n",
    "from tensorflow.keras.preprocessing.image import img_to_array #carrega funcao para converter imagem para array\n",
    "from PIL import Image\n",
    "#Funcao que remove quebra de linha\n",
    "def remove_spaces(cell):  \n",
    "    return cell.replace('\\n',' ')\n",
    "#Converte que carrega a image e depois convertte para array\n",
    "def get_array(image_path):\n",
    "    img = load_img(\"D:/SiDi/Project/Modulo II/dataset/b-t4sa_imgs\" + '/' + image_path, target_size=(image_height, image_width), color_mode='grayscale')\n",
    "\n",
    "    return img_to_array(img)\n",
    "\n",
    "\n",
    "#Mapeaa os tipos de classes existente nos rotulos de predicoes\n",
    "def to_one_hot(y, class_mapping, num_classes):\n",
    "    y_int = y.map(class_mapping)\n",
    "    return to_categorical(y_int, num_classes)\n",
    "\n",
    "#X_text = df['text'].apply(remove_spaces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Numero de classes do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fdL7BAx0VdB5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEG': 0, 'NEU': 1, 'POS': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_classes = df['sent_text'].nunique()\n",
    "#Faz o mapeeamento da classe com o id\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['sent_text']))}\n",
    "class_mapping\n",
    "#y_int = df['sent_text'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>768097808037605376-1</td>\n",
       "      <td>0.919993</td>\n",
       "      <td>0.055681</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>RT @hoseokahhh: \"who is this song forwhat do i...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097808037605376-1.jpg</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>768097833215938560-1</td>\n",
       "      <td>0.864726</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.076834</td>\n",
       "      <td>RT @ARapperSaid_: “I ain’t come over here for ...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097833215938560-1.jpg</td>\n",
       "      <td>398</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>768097929659817984-1</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-1.jpg</td>\n",
       "      <td>489</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>768097929659817984-2</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-2.jpg</td>\n",
       "      <td>983</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>768097929659817984-3</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-3.jpg</td>\n",
       "      <td>1326</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0            image_name       NEG       NEU       POS  \\\n",
       "0      0           0  768097808037605376-1  0.919993  0.055681  0.024326   \n",
       "1      1           1  768097833215938560-1  0.864726  0.058440  0.076834   \n",
       "2      2           2  768097929659817984-1  0.907574  0.061396  0.031029   \n",
       "3      3           3  768097929659817984-2  0.907574  0.061396  0.031029   \n",
       "4      4           4  768097929659817984-3  0.907574  0.061396  0.031029   \n",
       "\n",
       "                                                text sent_text  sent_image  \\\n",
       "0  RT @hoseokahhh: \"who is this song forwhat do i...       NEG           0   \n",
       "1  RT @ARapperSaid_: “I ain’t come over here for ...       NEG           0   \n",
       "2  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "3  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "4  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "\n",
       "                            image_path  image_height  image_width  \n",
       "0  data/76809/768097808037605376-1.jpg           449          449  \n",
       "1  data/76809/768097833215938560-1.jpg           398          593  \n",
       "2  data/76809/768097929659817984-1.jpg           489         1132  \n",
       "3  data/76809/768097929659817984-2.jpg           983         1123  \n",
       "4  data/76809/768097929659817984-3.jpg          1326         1110  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jCbAzR3KVdB5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"docs = {}\\n#Identificador da imagem para agrupamento\\nvalues = df['image_name'].value_counts()[0:100]\\nfor i in values.index:\\n    docs[i] = df[df['image_name'] == i].sort_values(by=['image_name'])#adicionar numa lista de documentos no chave valor\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"docs = {}\n",
    "#Identificador da imagem para agrupamento\n",
    "values = df['image_name'].value_counts()[0:100]\n",
    "for i in values.index:\n",
    "    docs[i] = df[df['image_name'] == i].sort_values(by=['image_name'])#adicionar numa lista de documentos no chave valor\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xWwrVJ8WaJL5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"len(df['image_name'][0])\\ndf['image_name'][0]\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"len(df['image_name'][0])\n",
    "df['image_name'][0]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9WIkvJ_1VdB6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Iterar sobre cada imagem representad apenas com a chave\\nX_keys = [key for key in docs.keys()]\\n#Divide em teste e e validação\\ntrain_size = int(len(X_keys)*0.70)\\nprint(len(X_keys[:train_size]))\\nprint(len(X_keys[train_size:]))'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Iterar sobre cada imagem representad apenas com a chave\n",
    "X_keys = [key for key in docs.keys()]\n",
    "#Divide em teste e e validação\n",
    "train_size = int(len(X_keys)*0.70)\n",
    "print(len(X_keys[:train_size]))\n",
    "print(len(X_keys[train_size:]))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = []\n",
    "X_train_image = []\n",
    "y_train = []\n",
    "image_path = []\n",
    "y_total = []\n",
    "img_total = []\n",
    "text_total = []\n",
    "page_total = []\n",
    "doc_total = []\n",
    "target_total = []\n",
    "\n",
    "for i in range(1,len(df[:71]),1):\n",
    "    X_image = df[i-1:i]['image_path'].apply(get_array)\n",
    "    X_text = df[i-1:i]['text']\n",
    "    y = to_one_hot(df[ i-1:i]['sent_text'], class_mapping, num_classes)\n",
    "    \n",
    "    text_image = pd.concat([X_image, X_text], axis=1)\n",
    "    \n",
    "    image_path.extend( df[i-1:i]['image_path'])\n",
    "    X_train_text.extend(X_text)\n",
    "    X_train_image.extend(X_image)\n",
    "    y_train.extend(y)\n",
    "    y_total.append(y)\n",
    "    text_total.append(X_text)\n",
    "    img_total.append(X_image)\n",
    "    page_total.append( df[i-1:i]['image_name'])\n",
    "    doc_total.append( df[i-1:i]['image_name'])\n",
    "    target_total.append( df[i-1:i]['sent_text'])\n",
    "    \n",
    "    \n",
    "    \n",
    "X_train_text = pd.Series(X_train_text)\n",
    "X_train_image = pd.Series(X_train_image)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_total)\n",
    "len(text_total)\n",
    "len(img_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_text = []\n",
    "X_test_image = []\n",
    "y_test = []\n",
    "\n",
    "image_path = []\n",
    "y_total = []\n",
    "img_total = []\n",
    "text_total = []\n",
    "page_total = []\n",
    "doc_total = []\n",
    "target_total = []\n",
    "\n",
    "for i in range(1,len(df[70:101]),1):\n",
    "    X_image = df[i-1:i]['image_path'].apply(get_array)\n",
    "    X_text = df[i-1:i]['text']\n",
    "    y = to_one_hot(df[i-1:i]['sent_text'], class_mapping, num_classes)\n",
    "    \n",
    "    text_image = pd.concat([X_image, X_text], axis=1)\n",
    "    \n",
    "    X_test_text.extend(X_text)\n",
    "    X_test_image.extend(X_image)\n",
    "    y_test.extend(y)\n",
    "    y_total.append(y)\n",
    "    text_total.append(X_text)\n",
    "    img_total.append(X_image)\n",
    "    page_total.append(df[i-1:i]['image_name'])\n",
    "    doc_total.append(df[i-1:i]['image_name'])\n",
    "    target_total.append(df[i-1:i]['sent_text'])\n",
    "    \n",
    "    \n",
    "X_test_text = pd.Series(X_test_text)\n",
    "X_test_image = pd.Series(X_test_image)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hnxQmZqfL8Dx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_total), len(text_total), len(img_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oj-rAfeilKpY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEG': 0, 'NEU': 1, 'POS': 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IfAjT11aFT0"
   },
   "source": [
    "# Join Train and Test (Test and Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XRxLzx9RNC_J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_join_text = X_train_text.append(X_test_text)\n",
    "X_join_image = X_train_image.append(X_test_image)\n",
    "len(X_join_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be4vTzpm6tx5"
   },
   "source": [
    "# Carrega Dados para Validacao ou Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Skh1Ums27mow"
   },
   "source": [
    "# Carrega objeto de Dados para servir de entrada na rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "M1JOg-1rVdB8"
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \"\"\"\n",
    "    Class to handle loading and processing of raw datasets.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_source,\n",
    "                 alphabet=\" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\",\n",
    "                 input_size=1014, num_of_classes=3, alphabet_size=71):\n",
    "        \"\"\"\n",
    "        Initialization of a Data object.\n",
    "\n",
    "        Args:\n",
    "            data_source (str): Raw data file path\n",
    "            alphabet (str): Alphabet of characters to index\n",
    "            input_size (int): Size of input features\n",
    "            num_of_classes (int): Number of classes in data\n",
    "        \"\"\"\n",
    "        self.alphabet = alphabet\n",
    "        self.alphabet_size = len(self.alphabet)\n",
    "        self.dict = {}  # Maps each character to an integer\n",
    "        self.no_of_classes = num_of_classes\n",
    "        for idx, char in enumerate(self.alphabet):\n",
    "            self.dict[char] = idx + 1\n",
    "        self.length = input_size\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load raw data from the source file into data variable.\n",
    "\n",
    "        Returns: None\n",
    "\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for doc in self.data_source:\n",
    "            data.append(doc)\n",
    "        self.data = np.array(data)\n",
    "\n",
    "    def get_all_data(self):\n",
    "        \"\"\"\n",
    "        Return all loaded data from data variable.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray) Data transformed from raw to indexed form with associated one-hot label.\n",
    "\n",
    "        \"\"\"\n",
    "        data_size = len(self.data)\n",
    "        start_index = 0\n",
    "        end_index = data_size\n",
    "        batch_texts = self.data[start_index:end_index]\n",
    "        batch_indices = []\n",
    "        one_hot = np.eye(self.no_of_classes, dtype='int64')\n",
    "        classes = []\n",
    "        for c, s in batch_texts:\n",
    "            batch_indices.append(self.str_to_indexes(s))\n",
    "            c = int(c) - 1\n",
    "            classes.append(one_hot[c])\n",
    "        return np.asarray(batch_indices, dtype='int64'), np.asarray(classes)\n",
    "\n",
    "    def str_to_indexes(self, s):\n",
    "        \"\"\"\n",
    "        Convert a string to character indexes based on character dictionary.\n",
    "        \n",
    "        Args:\n",
    "            s (str): String to be converted to indexes\n",
    "\n",
    "        Returns:\n",
    "            str2idx (np.ndarray): Indexes of characters in s\n",
    "\n",
    "        \"\"\"\n",
    "        s = s.lower()\n",
    "        max_length = min(len(s), self.length)\n",
    "        str2idx = np.zeros(self.length, dtype='int64')\n",
    "        for i in range(1, max_length + 1):\n",
    "            c = s[-i]\n",
    "            if c in self.dict:\n",
    "                str2idx[i - 1] = self.dict[c]\n",
    "        return str2idx\n",
    "\n",
    "    def vectorize_sentences(self, data, char_indices):\n",
    "        X = []\n",
    "\n",
    "        for doc in data:\n",
    "        \n",
    "            x = [char_indices[w] if w in self.alphabet else 0 for w in doc.lower()]\n",
    "            x2 = np.eye(self.alphabet_size + 1)[x]\n",
    "            X.append(x2)\n",
    "            \n",
    "        return pad_sequences(X, maxlen=self.length, padding=\"pre\")\n",
    "\n",
    "    def get_target_data(self):\n",
    "        \"\"\"\n",
    "        Return all loaded data from data variable.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray) Data transformed from raw to indexed form with associated one-hot label.\n",
    "\n",
    "        \"\"\"\n",
    "        data_size = len(self.data)\n",
    "        start_index = 0\n",
    "        end_index = data_size\n",
    "        batch_texts = self.data[start_index:end_index]\n",
    "        batch_indices = []\n",
    "        one_hot = np.eye(self.no_of_classes, dtype='int64')\n",
    "        classes = []\n",
    "        for c, s in batch_texts:\n",
    "            c = int(c)\n",
    "            classes.append(one_hot[c])\n",
    "        return np.asarray(classes)\n",
    "\n",
    "    def get_data_3dim(self):\n",
    "        '''\n",
    "        transform training input to shape Number_of_Rows X MaxLen X Alphabet_size\n",
    "        this is need to be done to avoid the use of embedding layer, wich is not supported on the Tflite converter\n",
    "        '''\n",
    "        char_indices = dict((c, i) for i, c in enumerate(self.alphabet,1))\n",
    "        indices_char = dict((i, c) for i, c in enumerate(self.alphabet,1))\n",
    "\n",
    "        \n",
    "        train_data = self.vectorize_sentences(self.data, char_indices)\n",
    "        train_data.shape\n",
    "        return train_data\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcL2G6LK8s1F"
   },
   "source": [
    "# Instancia os Objetos (Data) Treinamento e Validacao a partir do  conjunto de dados Treinamento e Validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "njYtvIfTVdB8"
   },
   "outputs": [],
   "source": [
    "training_data = Data(data_source=X_train_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "training_data.load_data()\n",
    "\n",
    "validation_data = Data(data_source=X_test_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "validation_data.load_data()\n",
    "    \n",
    "\n",
    "X_train_text = training_data.get_data_3dim()\n",
    "X_test_text = validation_data.get_data_3dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JsPJ43B9QUP"
   },
   "source": [
    "# Converte de Imagem para Array Numpy - image_to_numpy(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "tVUP1aAPVdB9"
   },
   "outputs": [],
   "source": [
    "def image_to_numpy(image_df):\n",
    "    all_images = []\n",
    "    for i in range(len(image_df)):\n",
    "        all_images.append(image_df.iloc[i])  \n",
    "    return np.array(all_images)\n",
    "\n",
    "X_train_image = image_to_numpy(X_train_image)\n",
    "X_test_image = image_to_numpy(X_test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nf2VBXRxD_An"
   },
   "outputs": [],
   "source": [
    "merge_data = Data(data_source=X_join_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "merge_data.load_data()\n",
    "    \n",
    "\n",
    "X_join_text = merge_data.get_data_3dim()\n",
    "\n",
    "X_join_image = image_to_numpy(X_join_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ijk7PaQB9hTt"
   },
   "source": [
    "# Imprime o Shape do Objeto de Treinamento Convertido Array Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ljs8GVLVVdB9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssjgpvFe91Wg"
   },
   "source": [
    "# (01) - Conjunto de Dados de Validacao - Declara a Classe ImageValidationCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oW8DDL5zVdB9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SiDi\\Project\\Modulo II\\github\\keras-tf-gpu\\keras-tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 224, 224, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 217, 217, 32)      2080      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 31, 31, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " encoded_image (Dense)       (None, 256)               205056    \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,803\n",
      "Trainable params: 244,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "def predict(model, X_test_image, batch_size=32):\n",
    "    y_predict = np.round(model.predict(X_test_image))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class ImageValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_image,y_test, metric = 'kappa'):\n",
    "        self.X_test_image = X_test_image\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, X_test_image)\n",
    "        #true_labels = [label2Idx[x[1]] for x in self.test_data]\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metric)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)\n",
    "\n",
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(32, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='tanh', name='encoded_image')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_image)\n",
    "model_image = Model(image_input, output)\n",
    "model_image.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "print(model_image.summary())\n",
    "\n",
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "with tf.device(gpu.name):\n",
    "    for i in range(n_repeats):\n",
    "        checkpoint = ImageValidationCheckpoint(model_file, X_test_image, y_test, metric=optimize_for)\n",
    "        model_image.fit(X_train_image, y_train, epochs=40, batch_size=32,\n",
    "                         validation_data=(X_test_image, y_test)\n",
    "                         ,callbacks = [checkpoint])\n",
    "        exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_image.save('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEQeKf8hAGTJ"
   },
   "source": [
    "# (01) - Configuracao da Arquitetura I \n",
    "\n",
    "1.   Conv2D -> Inicial(32 (8,8)) e Oculta (32 (6,6))\n",
    "2.   MaxPooling -> (32 (6,6))\n",
    "3.   Loss -> categorical_crossentropy   \n",
    "4.   optimizer -> optimizers.RMSprop(lr=1e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOcZeNhu_h3R"
   },
   "outputs": [],
   "source": [
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(32, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='tanh', name='encoded_image')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_image)\n",
    "model_image = Model(image_input, output)\n",
    "model_image.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "                    metrics=['acc'])\n",
    "print(model_image.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHf7mf8gB3En"
   },
   "source": [
    "# (01) - Avaliacao da Arquitetura I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCL1J9q9Bmga"
   },
   "outputs": [],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = ImageValidationCheckpoint(model_file, X_test_image, y_test, metric=optimize_for)\n",
    "    model_image.fit(X_train_image, y_train, epochs=40, batch_size=32,\n",
    "                     validation_data=(X_test_image, y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_image.save('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuWVpNqrCL22"
   },
   "source": [
    "# (02) - Conjunto de Dados de Validacao Declara a Classe ImageValidationCheckpoint \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MonFCIzTVdB-"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_test_image, batch_size=32):\n",
    "    y_predict = np.round(model.predict(X_test_image))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class ImageValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_image,y_test, metric = 'kappa'):\n",
    "        self.X_test_image = X_test_image\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, X_test_image)\n",
    "        #true_labels = [label2Idx[x[1]] for x in self.test_data]\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            #'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metrics)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiW3iTc2CcGY"
   },
   "source": [
    "# (02) - Configuracao da Arquitetura II\n",
    "\n",
    "\n",
    "1.   Conv2D -> Inicial(16,(8,8)) e Oculta (16,(6, 6))\n",
    "2.   MaxPooling -> (6,6)\n",
    "3.   Loss -> categorical_crossentropy   \n",
    "4.   optimizer -> optimizers.RMSprop(lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UP6_lJFCZpO"
   },
   "outputs": [],
   "source": [
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(16, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='tanh', name='encoded_image')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_image)\n",
    "model_image = Model(image_input, output)\n",
    "model_image.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "print(model_image.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTUc6EsHN77K"
   },
   "source": [
    "# (02) - Avaliacao da Arquitetura II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfoSeydlVdB_"
   },
   "outputs": [],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = ImageValidationCheckpoint(model_file, X_test_image, y_test, metric=optimize_for)\n",
    "    model_image.fit(X_train_image, y_train, epochs=40, batch_size=16,\n",
    "                     validation_data=(X_test_image, y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_image.save('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIG409EYP5rt"
   },
   "source": [
    "# Teste o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTSdtUDqVdB_"
   },
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_image.predict(X_test_image)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAOCHOr3QL-U"
   },
   "source": [
    "# Exporte o modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RP51R_dVdCA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( checkpoint.history, open( \"image-model-aibox40.pickle\", \"wb\" ) )\n",
    "print(checkpoint.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77vZRztnVdCA"
   },
   "outputs": [],
   "source": [
    "print(avg_result)\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzyoaPAXyNIz"
   },
   "source": [
    "# (03) - Conjunto de Dados de Validacao Declara a Classe ImageValidationCheckpoint \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpxgPeiEVdCA"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_test_text, batch_size=32):\n",
    "    y_predict = np.round(model.predict(X_test_text))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class TextValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_text,y_test, metric = 'kappa'):\n",
    "        self.X_test_text = X_test_text\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, self.X_test_text)\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            #'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metrics)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7m7kuUiyV73"
   },
   "source": [
    "# (03) - Configuracao da Arquitetura II\n",
    "\n",
    "\n",
    "1.   Conv2D -> Inicial(16,(8,8)) e Oculta (16,(6, 6))\n",
    "2.   MaxPooling -> (6,6)\n",
    "3.   Loss -> categorical_crossentropy   \n",
    "4.   optimizer -> optimizers.RMSprop(lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ua-FGoCtygdK"
   },
   "outputs": [],
   "source": [
    "text_input = Input(shape=(input_size, alphabet_size), name='text_input', dtype='float32')\n",
    "\n",
    "x = Convolution1D(nb_filter=50, filter_length=3,\n",
    "                     border_mode='valid', activation='tanh',\n",
    "                     input_shape=(input_size, alphabet_size))(text_input)\n",
    "\n",
    "for cl in conv_layers:\n",
    "    x = Convolution1D(cl[0], cl[1])(x)\n",
    "    #x = ThresholdedReLU(threshold)(x)\n",
    "    if cl[2] != -1:\n",
    "        x = MaxPooling1D(cl[2])(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for fl in fully_connected_layers:\n",
    "    x = Dense(fl)(x)\n",
    "    #x = ThresholdedReLU(threshold)(x)\n",
    "    x = Dropout(dropout_p)(x)\n",
    "\n",
    "encoded_text = Dense(256, activation='tanh', name='encoded_text')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_text)\n",
    "model_text = Model(text_input, output)\n",
    "model_text.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "print(model_text.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C6Wsc_Cymvg"
   },
   "source": [
    "# (03) - Treino da Rede Neural da Arquitetura III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxJJyKEPVdCA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = TextValidationCheckpoint(model_file, X_test_text, y_test, metric=optimize_for)\n",
    "    model_text.fit(X_train_text, y_train, epochs=40, batch_size=16,\n",
    "                     validation_data=(X_test_text, y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_text.save('model_ness_txt_image_v1.h5')\n",
    "\n",
    "model_text.save('model_ness_txt_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCPVTFx1zf2y"
   },
   "source": [
    "# (03) Avaliação da Rede Neural III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpNfCXAnVdCB"
   },
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_text.predict(X_test_text)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3IjxHmrzpp3"
   },
   "source": [
    "# (03) Exportação do Modelo da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IW_JdzNuVdCB"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( checkpoint.history, open( \"text-model-aibox40.pickle\", \"wb\" ) )\n",
    "print(checkpoint.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCWRUDEqzxTM"
   },
   "source": [
    "# (04) - Conjunto de Dados de Validacao Declara a Classe ImageValidationCheckpoint \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jb96kKeGVdCB"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_test_text, X_test_image, batch_size=32):\n",
    "    y_predict = np.round(model.predict([X_test_text, X_test_image]))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class ValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_text, X_test_image,y_test, metric = 'kappa'):\n",
    "        self.X_test_text = X_test_text\n",
    "        self.X_test_image = X_test_image\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, self.X_test_text, X_test_image)\n",
    "        #true_labels = [label2Idx[x[1]] for x in self.test_data]\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            #'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metrics)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnjWJgPj3MH2"
   },
   "source": [
    "# (04) Configuração da Arquitetura (Imagem + Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zX8rleYm3V4g"
   },
   "outputs": [],
   "source": [
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(16, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='tanh', name='encoded_image')(x)\n",
    "\n",
    "\n",
    "\n",
    "text_input = Input(shape=(input_size, alphabet_size), name='text_input', dtype='float32')\n",
    "\n",
    "x = Convolution1D(nb_filter=50, filter_length=3,\n",
    "                     border_mode='valid', activation='tanh',\n",
    "                     input_shape=(input_size, alphabet_size))(text_input)\n",
    "\n",
    "for cl in conv_layers:\n",
    "    x = Convolution1D(cl[0], cl[1])(x)\n",
    "    #x = ThresholdedReLU(threshold)(x)\n",
    "    if cl[2] != -1:\n",
    "        x = MaxPooling1D(cl[2])(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for fl in fully_connected_layers:\n",
    "    x = Dense(fl)(x)\n",
    "    #x = ThresholdedReLU(threshold)(x)\n",
    "    x = Dropout(dropout_p)(x)\n",
    "\n",
    "encoded_text = Dense(256, activation='tanh', name='encoded_text')(x)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_image], axis=-1, name='concatanated')\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(concatenated)\n",
    "model_hybrid = Model([text_input, image_input], output)\n",
    "model_hybrid.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "model_hybrid.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6y-UNhs35Jd"
   },
   "source": [
    "# (04) - Treinamento da Rede Neural = Texto e Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seXwiuVqVdCC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = ValidationCheckpoint(model_file, X_test_text, X_test_image, y_test, metric=optimize_for)\n",
    "    model_hybrid.fit([X_train_text, X_train_image], y_train, epochs=40, batch_size=32,\n",
    "                     validation_data=([X_test_text, X_test_image], y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_hybrid.save('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7_XAAcT49RZ"
   },
   "source": [
    "# (04)  Exportação Modelo da Rede Neural ( Texto & Imagem )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9a_mHV4VdCC"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( checkpoint.history, open( \"text-image-model-aibox40.pickle\", \"wb\" ) )\n",
    "print(checkpoint.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACuipGVW5Dcg"
   },
   "source": [
    "# 04 Single Page Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eaqcr-vMVdCD"
   },
   "outputs": [],
   "source": [
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOzWXFfS5XBl"
   },
   "source": [
    "#(04) Recarrega Modelo Hibrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WD-7fRQaVdCD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_hybrid = load_model('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcMeIPJm5imp"
   },
   "source": [
    "# (04) Avalia modelo Hibrido (Texto & Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYU39etIVdCD"
   },
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_hybrid.predict([X_test_text, X_test_image])\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bksymW4qNvrL"
   },
   "outputs": [],
   "source": [
    "#X_join_text = X_train_text.append(X_test_text)\n",
    "#X_image = X_train_image.append(X_test_image)\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApW806-tZHfM"
   },
   "source": [
    "# Fase de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpcPXV7FZFb8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_hybrid.predict([X_join_text, X_join_image])\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAw1DmFPuREU"
   },
   "source": [
    "# Mapping Id of Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuDlLakynaAo"
   },
   "outputs": [],
   "source": [
    "id_class_mapping = {idx:label for idx,label in enumerate(np.unique(df['sent_text']))}\n",
    "id_class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M86pz8ZvVsl"
   },
   "outputs": [],
   "source": [
    "pred_class = []\n",
    "for i in range(len(y_pred)):\n",
    "  pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "  pred_class.append(id_class_mapping[pred[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HOcAUz1watX"
   },
   "source": [
    "# To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suuDHSCQwclR"
   },
   "outputs": [],
   "source": [
    "df_seq = pd.DataFrame({'image_name': doc_order, 'image_page': page_order, 'sent_text': target_order, 'image_predict': pred_class})\n",
    "\n",
    "df_seq.to_csv('sequence-classifier-output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-n_rP8zh7I7z"
   },
   "outputs": [],
   "source": [
    "df_seq['match'] = np.where(df_seq['sent_text']==df_seq['image_predict'], \n",
    "                                           'yes', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QOmRMkq75Ff"
   },
   "outputs": [],
   "source": [
    "df_seq['match'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRERUqTK9Wa5"
   },
   "outputs": [],
   "source": [
    "df_seq.head(n=2970)[-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8lWsxakBkuq"
   },
   "outputs": [],
   "source": [
    "df_seq['match'].apply(lambda x: x == 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ObWteqn-mTP"
   },
   "outputs": [],
   "source": [
    "df_seq[df_seq['match'].apply(lambda x: x == 'no')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzaa9B1tZPCa"
   },
   "source": [
    "# Mapping Real Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMY4G_qLZFcA"
   },
   "outputs": [],
   "source": [
    "y_real = np.array(real_mapping_class)\n",
    "\n",
    "real_mapping_class_seq = []\n",
    "for i in range(len(y_real)):\n",
    "  pred = np.where(y_real[i] == np.amax(y_real[i]))\n",
    "  real_mapping_class_seq.append(pred[0][0])\n",
    "  #print(pred[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQM0R8_HiZz1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72jTmi8ZZbb4"
   },
   "source": [
    "# Mapping Pred Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocktA3u9ZFcB"
   },
   "outputs": [],
   "source": [
    "pred_mapping_class = []\n",
    "for i in range(len(y_pred)):\n",
    "  pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "  pred_mapping_class.append(pred[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o22xZKIZZnMj"
   },
   "source": [
    "# Export Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kzgH6PIZFcB"
   },
   "outputs": [],
   "source": [
    "df['real_map_class'] = real_mapping_class_seq\n",
    "df['pred_map_class'] = pred_mapping_class\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv('ness-seq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJVntxnhZ6WP"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pw6ZPeq76RB"
   },
   "source": [
    "#04 Realiza o mapeamento da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2P5Reb_VdCD"
   },
   "outputs": [],
   "source": [
    "num_classes = df['sent_text'].nunique()\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['sent_text']))}\n",
    "y_int = df['sent_text'].map(class_mapping)\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgRhU8wbZ3dI"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvqttvg58I7v"
   },
   "source": [
    "# Verifica a taxa de acertos com classe predita e classe esperada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EFj2QBBVdCD"
   },
   "outputs": [],
   "source": [
    "y_f = []\n",
    "for i in range(len(y_pred)):\n",
    "    pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "    y_f.append(pred[0][0])\n",
    "\n",
    "print(classification_report(Y_test, y_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eL5wgZpxVdCD"
   },
   "outputs": [],
   "source": [
    "{'anexo': 0, 'anotacao': 1, 'autos': 2, 'branco': 3, 'certidao': 4, \n",
    " 'citacao': 5, 'decisao': 6, 'intimacao': 7, 'jec': 8, 'lixo': 9, 'movimentacao': 10, \n",
    " 'peticao': 11, 'procuracao': 12, 'setenca': 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gF8dS_6Fi3vM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTeaVqCc8aoq"
   },
   "source": [
    "#Prediz com a base de treimaneto texto e image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXBAxnsHVdCE"
   },
   "outputs": [],
   "source": [
    "y_pred = model_hybrid.predict([X_train_text, X_train_image])\n",
    "y_f = []\n",
    "Y_train = np.argmax(y_train, axis=1) # Convert one-hot to index\n",
    "for i in range(len(y_pred)):\n",
    "    pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "    y_f.append(pred[0][0])\n",
    "\n",
    "print(classification_report(Y_train, y_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aXjq_1NVdCE"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "lens = []\n",
    "for key in X_keys[:train_size]:\n",
    "    X.append([[class_mapping[i]] for i in list(docs[key]['sent_text'])])\n",
    "    lens.append(len(X[-1]))\n",
    "X_train = np.concatenate(X)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmJ_t5PKVdCE"
   },
   "outputs": [],
   "source": [
    "## OS EXPERIMENTOS ACABAM AQUI, EMBAIXO APENAS TESTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZxoLaH7VdCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Eur_KVMVdCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YL4BsT0fVdCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3PxjKpwVdCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WrJJS2AVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_x7ug-YxVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0qxDy0SVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pqy8xuEVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZp3ARymVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XISJ73vVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENVgmp4QVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUU-_QIbVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULbWYABRVdCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyhjXtpWVdCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpA-DtzTVdCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBGx_VIQVdCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQ8kZTJBVdCG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn.hmm import MultinomialHMM\n",
    "\n",
    "h = MultinomialHMM(n_components=12)\n",
    "h.fit(X_train, lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO4NItvtVdCG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_hmm_pp_test = []\n",
    "y_hmm_test = []\n",
    "y_test_true_hmm = []\n",
    "for i in X_keys[train_size:]:\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot(docs[i]['sent_text'], class_mapping, num_classes)\n",
    "    \n",
    "    X_test_image = image_to_numpy(X_image)\n",
    "    test_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    test_data.load_data()\n",
    "\n",
    "\n",
    "    X_test_text = test_data.get_data_3dim()\n",
    "\n",
    "    \n",
    "    X_hmm_test = model_hybrid.predict([X_test_text, X_test_image])\n",
    "    \n",
    "    results_to_int  = np.argmax(X_hmm_test, axis=1)\n",
    "    y_hmm = h.decode(results_to_int.reshape(-1,1))\n",
    "    y_hmm_test.extend(y_hmm[1])\n",
    "    y_int = docs[i]['sent_text'].map(class_mapping)\n",
    "    y_test_true_hmm.extend(y_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Sqg5vESVdCG"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_true_hmm, y_hmm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJYStsC8VdCG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = df['sent_text'].nunique()\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['sent_text']))}\n",
    "print(class_mapping)\n",
    "for i in range(len(docs['j3'])):\n",
    "    print(class_mapping[docs['j3']['sent_text'].iloc[i]], c[1][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FGSgt4sVdCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beoq-va_VdCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfDeuTjDVdCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otjoE6v4VdCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSQYc6dKVdCH"
   },
   "outputs": [],
   "source": [
    "from attention_decoder import AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-1xEoCGVdCH"
   },
   "outputs": [],
   "source": [
    "\n",
    "def temporalize(X, y, lookback):\n",
    "    output_X = []\n",
    "    output_y = []\n",
    "    for i in range(len(X)-lookback-1):\n",
    "        t = []\n",
    "        for j in range(1,lookback+1):\n",
    "            # Gather past records upto the lookback period\n",
    "            t.append(X[[(i+j+1)], :])\n",
    "        output_X.append(t)\n",
    "    return output_X, y\n",
    "\n",
    "def get_lstm_model_with_attention(num_classes, timesteps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(timesteps, num_classes), return_sequences=True))\n",
    "    model.add(LSTM(100, input_shape=(timesteps, num_classes), return_sequences=True))\n",
    "    model.add(LSTM(100, input_shape=(timesteps, num_classes), return_sequences=True))\n",
    "    model.add(AttentionDecoder(100, num_classes))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "def get_lstm_model_simple_reconstructor(num_classes, timesteps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='relu', input_shape=(timesteps,num_classes), return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(num_classes)))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_lstm_model_autoencoder(num_classes, timesteps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='relu', input_shape=(timesteps,num_classes), return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "    model.add(RepeatVector(timesteps))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(num_classes)))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def treinar_lstm_ac(X,y, timesteps, num_classes, model_lstm):\n",
    "    \n",
    "    X_train, y_train = temporalize(X, y, timesteps)\n",
    "    history = model_lstm.fit(X_train, y_train, epochs=100, batch_size=4)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def treinar_lstm_ac_2(X,y, timesteps, num_classes, model_lstm):\n",
    "    #TimeSeries to Supervised\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    print(y.shape)\n",
    "    print(X.shape)\n",
    "    for i in range(timesteps, len(X)):\n",
    "            X_train.append(X[i-timesteps : i])\n",
    "            y_train.append(y[i-timesteps : i])\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    #X_train = np.stack(X_train, axis=0)\n",
    "        \n",
    "    #Dimensão, número de linhas, número de colunas(timesteps) e número de features\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1], y_train.shape[2]))\n",
    "    #regressor.add(LSTM(units = 50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "   \n",
    "    #treinar\n",
    "    #validation_split = 0.3\n",
    "    history = model_lstm.fit(X_train, y_train, epochs=50, batch_size=4)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def get_lstm_model(num_classes, timesteps):\n",
    "    input_layer = Input(shape=(timesteps, num_classes), name='input', dtype='float32')\n",
    "    #x = Conv1D(filters=256, kernel_size=4, activation='relu', input_shape=(timesteps,num_classes))(input_layer)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    #x = MaxPooling1D(pool_size=3)(x)\n",
    "    #x = Flatten()(x)\n",
    "    #x = Dense(100, activation='relu')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(75, input_shape = (timesteps, num_classes), return_sequences=True),name='bilstm')(input_layer)\n",
    "    x = layers.Bidirectional(layers.LSTM(50, input_shape = (timesteps, num_classes)),name='bilstm2')(x)\n",
    "    #x = layers.LSTM(120, input_shape = (timesteps, num_classes))(input_layer)\n",
    "    #x = Dense(12, activation='relu')(x)\n",
    "    #Criar Output Layer\n",
    "    output = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model_lstm = Model(input_layer, output)\n",
    "    #compilar\n",
    "    model_lstm.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "    \n",
    "    model_lstm.summary()\n",
    "    return model_lstm\n",
    "\n",
    "def data_to_timesteps(X):\n",
    "    X_train = []\n",
    "    for i in range(timesteps, len(X)):\n",
    "            X_train.append(X[i-timesteps : i])\n",
    "            \n",
    "    X_train = np.array(X_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    return X_train\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "def treinar_lstm(X,y, timesteps, num_classes, model_lstm):\n",
    "    #TimeSeries to Supervised\n",
    "    X_train = []\n",
    "    y_train = y\n",
    "    \n",
    "    for i in range(timesteps, len(X)):\n",
    "            X_train.append(X[i-timesteps : i])\n",
    "            \n",
    "    X_train = np.array(X_train)\n",
    "    \n",
    "    #X_train = np.stack(X_train, axis=0)\n",
    "        \n",
    "    #Dimensão, número de linhas, número de colunas(timesteps) e número de features\n",
    "    print(X_train.shape)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    #regressor.add(LSTM(units = 50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "   \n",
    "    #treinar\n",
    "    #validation_split = 0.3\n",
    "    history = model_lstm.fit(X_train, y_train, epochs=150, batch_size=4)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def to_one_hot_ts(y, class_mapping, num_classes, timesteps):\n",
    "    y_int = y.map(class_mapping)\n",
    "    y_int = y_int[timesteps:]\n",
    "    \n",
    "    return to_categorical(y_int, num_classes)\n",
    "\n",
    "def decode_timeseries(y_pred):\n",
    "    y_decoded = []\n",
    "    cont = 1\n",
    "    len_y_true = len(y_pred) + timesteps - 1\n",
    "    for i in range(len(y_pred) + timesteps - 1):\n",
    "        if i < len(y_pred):\n",
    "            y_decoded.append(np.argmax(y_pred[i][0]))\n",
    "        else:\n",
    "            y_decoded.append(np.argmax(y_pred[-1][cont]))\n",
    "            cont += 1\n",
    "            \n",
    "    return y_decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2eRCDGNVdCI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bad results\n",
    "timesteps = 5\n",
    "model_lstm = get_lstm_model(num_classes, timesteps)\n",
    "y_train_lf = []\n",
    "X_lf_pp_train = []\n",
    "y_true_train_docs = []\n",
    "for i in X_keys[:train_size]:\n",
    "    docs[i]['sent_text_t1'] = docs[i]['sent_text'].shift(-1)\n",
    "    docs[i].dropna(inplace = True)\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    \n",
    "    y = to_one_hot_ts(docs[i]['sent_text_t1'], class_mapping, num_classes, timesteps)\n",
    "    X_train_image = image_to_numpy(X_image)\n",
    "    training_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    training_data.load_data()\n",
    "\n",
    "\n",
    "    X_train_text = training_data.get_data_3dim()\n",
    "\n",
    "    \n",
    "    X_lf = model_hybrid.predict([X_train_text, X_train_image])\n",
    "    X_lf_pp = np.eye(X_lf.shape[1])[X_lf.argmax(1)]\n",
    "    \n",
    "    y_true_train_docs.append(y)\n",
    "    X_lf_pp_train.append(data_to_timesteps(X_lf_pp))\n",
    "\n",
    "\n",
    "    history = treinar_lstm(X_lf_pp, y, timesteps, num_classes, model_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmmWXgf7VdCJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y61aDL3hVdCJ"
   },
   "outputs": [],
   "source": [
    "y_true_train = []\n",
    "y_pred_train = []\n",
    "for i in range(len(y_true_train_docs)):\n",
    "    y_true_train.extend(y_true_train_docs[i])\n",
    "    y_pred = model_lstm.predict(X_lf_pp_train[i])\n",
    "    y_pred_train.extend(y_pred)\n",
    "\n",
    "print(np.array(y_true_train).shape)\n",
    "print(np.array(y_pred_train).shape)   \n",
    "print(one_hot_decode(y_true_train))\n",
    "print(one_hot_decode(y_pred_train))\n",
    "print(classification_report(one_hot_decode(y_true_train), one_hot_decode(y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bsq4gyMCVdCK"
   },
   "outputs": [],
   "source": [
    "X_lf_pp_test = []\n",
    "y_true_test_docs = []\n",
    "for i in X_keys[train_size:]:\n",
    "    docs[i]['sent_text_t1'] = docs[i]['sent_text'].shift(-1)\n",
    "    docs[i].dropna(inplace = True)\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot_ts(docs[i]['sent_text_t1'], class_mapping, num_classes, timesteps)\n",
    "    \n",
    "    X_test_image = image_to_numpy(X_image)\n",
    "    test_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    test_data.load_data()\n",
    "\n",
    "    X_test_text = test_data.get_data_3dim()\n",
    "    X_lf_test = model_hybrid.predict([X_test_text, X_test_image])\n",
    "    X_lf_test_pp = np.eye(X_lf_test.shape[1])[X_lf_test.argmax(1)]\n",
    "    \n",
    "    y_true_test_docs.append(y)\n",
    "    X_lf_pp_test.append(data_to_timesteps(X_lf_test_pp))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaMGGfKJVdCK"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "for i in range(len(y_true_test_docs)):\n",
    "    y_true_test.extend(y_true_test_docs[i])\n",
    "    y_pred = model_lstm.predict(X_lf_pp_test[i])\n",
    "    y_pred_test.extend(y_pred)\n",
    "\n",
    "print(np.array(y_true_test).shape)\n",
    "print(np.array(y_pred_test).shape)                   \n",
    "print(classification_report(one_hot_decode(y_true_test), one_hot_decode(y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8a5W_7xVdCK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xeQViD0lVdCK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L32yXseJVdCL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGXabe7GVdCL"
   },
   "source": [
    "## SEQ TO SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MKCABwNVdCL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timesteps = 3\n",
    "model_lstm = get_lstm_model_with_attention(num_classes, timesteps)\n",
    "y_train_lf = []\n",
    "X_lf_pp_train = []\n",
    "y_true_train_docs = []\n",
    "for i in X_keys[:train_size]:\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot_ts(docs[i]['sent_text'], class_mapping, num_classes, timesteps)\n",
    "    \n",
    "    X_train_image = image_to_numpy(X_image)\n",
    "    training_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    training_data.load_data()\n",
    "\n",
    "\n",
    "    X_train_text = training_data.get_data_3dim()\n",
    "\n",
    "    \n",
    "    X_lf = model_hybrid.predict([X_train_text, X_train_image])\n",
    "    X_lf_pp = np.eye(X_lf.shape[1])[X_lf.argmax(1)]\n",
    "    \n",
    "    y_true_train_docs.append(data_to_timesteps(y))\n",
    "    X_lf_pp_train.append(data_to_timesteps(X_lf_pp))\n",
    "    history = treinar_lstm_ac_2(X_lf_pp, y, timesteps, num_classes, model_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KshVhrPSVdCL"
   },
   "outputs": [],
   "source": [
    "y_true_train = []\n",
    "y_pred_train = []\n",
    "for i in range(len(y_true_train_docs)):\n",
    "    y_true_train.extend(decode_timeseries(y_true_train_docs[i]))\n",
    "    y_pred = model_lstm.predict(X_lf_pp_train[i])\n",
    "    y_pred_train.extend(decode_timeseries(y_pred))\n",
    "\n",
    "print(y_true_train)\n",
    "print(y_pred_train)                   \n",
    "print(classification_report(y_true_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdY-JdOzVdCL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_lf_pp_test = []\n",
    "y_true_test_docs = []\n",
    "for i in X_keys[train_size:]:\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot_ts(docs[i]['sent_text'], class_mapping, num_classes, timesteps)\n",
    "    \n",
    "    X_test_image = image_to_numpy(X_image)\n",
    "    test_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    test_data.load_data()\n",
    "\n",
    "    X_test_text = test_data.get_data_3dim()\n",
    "    X_lf_test = model_hybrid.predict([X_test_text, X_test_image])\n",
    "    X_lf_test_pp = np.eye(X_lf_test.shape[1])[X_lf_test.argmax(1)]\n",
    "    \n",
    "    y_true_test_docs.append(data_to_timesteps(y))\n",
    "    X_lf_pp_test.append(data_to_timesteps(X_lf_test_pp))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-891lNvYVdCL"
   },
   "outputs": [],
   "source": [
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "for i in range(len(y_true_test_docs)):\n",
    "    y_true_test.extend(decode_timeseries(y_true_test_docs[i]))\n",
    "    y_pred = model_lstm.predict(X_lf_pp_test[i])\n",
    "    y_pred_test.extend(decode_timeseries(y_pred))\n",
    "\n",
    "print(y_true_test)\n",
    "print(y_pred_test)                   \n",
    "print(classification_report(y_true_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yateACcGVdCM",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuuDhoc_VdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bmS88ZQVdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oeW5NEFVdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3ycaj0IVdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRPLNUKjVdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nXc-LO-VdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pglp0YviVdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFKRqVI3VdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKUgr88-VdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cp_wQ_QcVdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReftgEDzVdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trQTdX0cVdCN"
   },
   "outputs": [],
   "source": [
    "print(X_train_text.shape)\n",
    "print(X_test_text.shape)\n",
    "print(X_train_image.shape)\n",
    "print(X_test_image.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X_text = np.concatenate((X_train_text, X_test_text))\n",
    "X_image = np.concatenate((X_train_image, X_test_image))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "\n",
    "print(X_text.shape)\n",
    "print(X_image.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMPoSOWIVdCN"
   },
   "outputs": [],
   "source": [
    "X_image = df['image_path'].apply(get_array)\n",
    "X_text = df['text']\n",
    "y = to_one_hot(df['sent_text'], class_mapping, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmZ3v32NVdCN"
   },
   "outputs": [],
   "source": [
    "text_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "text_data.load_data()\n",
    "X_text_array = text_data.get_data_3dim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNBu5Gb7VdCN"
   },
   "outputs": [],
   "source": [
    "def image_to_numpy(image_df):\n",
    "    all_images = []\n",
    "    for i in range(len(image_df)):\n",
    "        all_images.append(image_df.iloc[i])  \n",
    "    return np.array(all_images)\n",
    "\n",
    "X_image_array = image_to_numpy(X_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbaUkes3VdCO"
   },
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGNHWy5XVdCO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_hybrid = load_model('model_ness_txt_image_v1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTsV1ap6VdCO"
   },
   "outputs": [],
   "source": [
    "layer_name = 'concatanated'\n",
    "  \n",
    "layer_output = model_hybrid.get_layer(layer_name).output\n",
    "\n",
    "intermediate_model = Model(inputs=model_hybrid.input,outputs=layer_output)\n",
    "\n",
    "encoded_page = intermediate_model.predict([X_text_array, X_image_array])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgdUE8_-VdCO"
   },
   "outputs": [],
   "source": [
    "print(type(encoded_page))\n",
    "print(encoded_page.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CI6QOk2PVdCO"
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['encoded_page'] = []\n",
    "for i in encoded_page:\n",
    "    data['encoded_page'].append(i)\n",
    "    \n",
    "df_encoded = pd.DataFrame.from_dict(data)\n",
    "df = pd.concat([df, df_encoded], axis=1, sort=False)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfcjPzSTVdCO"
   },
   "outputs": [],
   "source": [
    "X_encoded = df['encoded_page']\n",
    "y = to_one_hot(df['sent_text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "X_test = np.stack(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ykt9TgD1VdCO"
   },
   "outputs": [],
   "source": [
    "encoded_input =Input(shape=(512,), name='encoded_page', dtype='float32')\n",
    "#x = Dense(1024, activation='relu')(encoded_page)\n",
    "output = Dense(num_classes, activation='softmax', name='output')(encoded_input)\n",
    "model = Model(encoded_input, output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIffiU-0VdCP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=400, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz-nN8rXVdCP"
   },
   "outputs": [],
   "source": [
    "#X = df[['encoded_page','image_page', 'image_name', 'sent_text']]\n",
    "X = df[['encoded_page', 'image_name', 'sent_text']]\n",
    "#X['sent_text_one_hot'] = to_one_hot(X['sent_text'])\n",
    "docs = {}\n",
    "\n",
    "values = X['image_name'].value_counts()\n",
    "print(values.index)\n",
    "print(values['12'])\n",
    "\n",
    "for i in values.index:\n",
    "    docs[i] = X[X['image_name'] == i].sort_values(by=['image_name']).drop(['image_name'], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SkU7it2VdCP"
   },
   "outputs": [],
   "source": [
    "def treinar_lstm(X,y, timesteps):\n",
    "    #TimeSeries to Supervised\n",
    "    X_train = []\n",
    "    y_train = y\n",
    "    \n",
    "    for i in range(timesteps, len(X)):\n",
    "            X_train.append(X[i-timesteps : i])\n",
    "            \n",
    "    X_train = np.array(X_train)\n",
    "    \n",
    "    #X_train = np.stack(X_train, axis=0)\n",
    "        \n",
    "    #Dimensão, número de linhas, número de colunas(timesteps) e número de features\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    #print(X_train.shape)\n",
    "    #print(y_train.shape)\n",
    "\n",
    "    #regressor.add(LSTM(units = 50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]), name='input', dtype='float32')\n",
    "    x = layers.Bidirectional(layers.LSTM(512, input_shape = (X_train.shape[1], X_train.shape[2])), name='bilstm')(input_layer)\n",
    "    #x = layers.LSTM(50, input_shape = (X_train.shape[1], X_train.shape[2]))(input_layer)\n",
    "    #Criar Output Layer\n",
    "    output = Dense(8, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model_lstm = Model(input_layer, output)\n",
    "    #compilar\n",
    "    model_lstm.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "    \n",
    "    model_lstm.summary()\n",
    "    #treinar\n",
    "    history = model_lstm.fit(X_train, y_train, epochs=150, batch_size=32, validation_split = 0.3)\n",
    "    \n",
    "    return model_lstm, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oBsM5_MVdCP"
   },
   "outputs": [],
   "source": [
    "def to_one_hot_ts(y, timesteps):\n",
    "    num_classes = y.nunique()\n",
    "    class_mapping = {label:idx for idx,label in enumerate(np.unique(y))}\n",
    "    y_int = y.map(class_mapping)\n",
    "    y_int = y_int[timesteps:]\n",
    "    \n",
    "    return to_categorical(y_int, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdMwR4qrVdCP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_test = docs['12'].drop(['sent_text', 'image_page], axis=1)\n",
    "df_test = docs['12'].drop(['sent_text'], axis=1)\n",
    "\n",
    "X_test = df_test['encoded_page']\n",
    "\n",
    "y_test = to_one_hot(docs['12']['sent_text'])\n",
    "timesteps = 5\n",
    "\n",
    "regressor, history = treinar_lstm(X_test,y_test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtICv_BJVdCP"
   },
   "outputs": [],
   "source": [
    "X_test = df_test['encoded_page'][5:]\n",
    "y_test = to_one_hot(docs['12']['sent_text'])\n",
    "\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "\n",
    "encoded_input =Input(shape=(512,), name='encoded_page', dtype='float32')\n",
    "#x = Dense(1024, activation='relu')(encoded_page)\n",
    "output = Dense(8, activation='softmax', name='output')(encoded_input)\n",
    "model = Model(encoded_input, output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "model.fit(X_test, y_test, epochs=1000, batch_size=32, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtDIMFyIVdCP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "0-2-multi-input-nn-hmm-30-mar-2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "keras-tf-gpu",
   "language": "python",
   "name": "keras-tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
