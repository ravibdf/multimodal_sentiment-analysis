{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umln0h6MLQqD",
    "tags": []
   },
   "source": [
    "# Importando as bibliotecas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append('./')\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import ThresholdedReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import models\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from tensorflow.keras import optimizers\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "import sklearn.metrics as sklm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KSRqGGEH2_Ny"
   },
   "outputs": [],
   "source": [
    "CHARNN_DATA_CONFIG = \"D:/SiDi/Project/Modulo II/github/multimodal-sentiment-analysis/rbsa2/charnn_cnn/charcnn_data_config.json\"\n",
    "charcnn_data_config = pd.read_json(CHARNN_DATA_CONFIG)\n",
    "\n",
    "CNN_DATA_CONFIG = \"D:/SiDi/Project/Modulo II/github/multimodal-sentiment-analysis/rbsa2/charnn_cnn/nn_config.json\"\n",
    "nn_data_config = pd.read_json(CNN_DATA_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "94AqsbHfVdB1"
   },
   "outputs": [],
   "source": [
    "#data_config = json.load(open(\"charcnn_data_config.json\")) #Leitura do arquivo de configuracao\n",
    "data_config = charcnn_data_config #Leitura do arquivo de configuracao\n",
    "\n",
    "#nn_config = json.load(open(\"nn_config.json\")) # Leitura de arquivo de configuracao, quais sao os parametros\n",
    "nn_config = nn_data_config # Leitura de arquivo de configuracao, quais sao os parametros\n",
    "\n",
    "alphabet_size = data_config[\"data\"][\"alphabet_size\"]+1 #tamanho do alfabeto\n",
    "input_size = data_config[\"data\"][\"input_size\"] #Tamanho do input de zi\n",
    "\n",
    "fully_connected_layers = nn_config[\"char_cnn_zhang\"][\"fully_connected_layers\"] #Camadas Conectadas\n",
    "conv_layers = nn_config[\"char_cnn_zhang\"][\"conv_layers\"] #Camadas Convulacionasi\n",
    "threshold = nn_config[\"char_cnn_zhang\"][\"threshold\"] # Limiar\n",
    "dropout_p = nn_config[\"char_cnn_zhang\"][\"dropout_p\"] #Taxa de Dropout\n",
    "embedding_size = nn_config[\"char_cnn_zhang\"][\"embedding_size\"] # Tamnho do Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "uFSgTy5kVdB2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470586\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH_URL  = \"D:/SiDi/Project/Modulo II/dataset/output/dataset_sidi_v1.2.csv\"\n",
    "df = pd.read_csv(DATASET_PATH_URL, sep='\\t')\n",
    "\n",
    "print(len(df))\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "      <th>POS</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_text</th>\n",
       "      <th>sent_image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>768097808037605376-1</td>\n",
       "      <td>0.919993</td>\n",
       "      <td>0.055681</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>RT @hoseokahhh: \"who is this song forwhat do i...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097808037605376-1.jpg</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>768097833215938560-1</td>\n",
       "      <td>0.864726</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.076834</td>\n",
       "      <td>RT @ARapperSaid_: “I ain’t come over here for ...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097833215938560-1.jpg</td>\n",
       "      <td>398</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>768097929659817984-1</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-1.jpg</td>\n",
       "      <td>489</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>768097929659817984-2</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-2.jpg</td>\n",
       "      <td>983</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>768097929659817984-3</td>\n",
       "      <td>0.907574</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>RT @blackedfriction: i hate telling people i l...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>0</td>\n",
       "      <td>data/76809/768097929659817984-3.jpg</td>\n",
       "      <td>1326</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0            image_name       NEG       NEU       POS  \\\n",
       "0      0           0  768097808037605376-1  0.919993  0.055681  0.024326   \n",
       "1      1           1  768097833215938560-1  0.864726  0.058440  0.076834   \n",
       "2      2           2  768097929659817984-1  0.907574  0.061396  0.031029   \n",
       "3      3           3  768097929659817984-2  0.907574  0.061396  0.031029   \n",
       "4      4           4  768097929659817984-3  0.907574  0.061396  0.031029   \n",
       "\n",
       "                                                text sent_text  sent_image  \\\n",
       "0  RT @hoseokahhh: \"who is this song forwhat do i...       NEG           0   \n",
       "1  RT @ARapperSaid_: “I ain’t come over here for ...       NEG           0   \n",
       "2  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "3  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "4  RT @blackedfriction: i hate telling people i l...       NEG           0   \n",
       "\n",
       "                            image_path  image_height  image_width  \n",
       "0  data/76809/768097808037605376-1.jpg           449          449  \n",
       "1  data/76809/768097833215938560-1.jpg           398          593  \n",
       "2  data/76809/768097929659817984-1.jpg           489         1132  \n",
       "3  data/76809/768097929659817984-2.jpg           983         1123  \n",
       "4  data/76809/768097929659817984-3.jpg          1326         1110  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "_dfcmoTpVdB3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent_text\n",
       "NEG    0.333333\n",
       "NEU    0.333333\n",
       "POS    0.333333\n",
       "Name: index, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica o balanceamento das classes\n",
    "classes = df.groupby('sent_text')['index'].nunique()/df.shape[0] #Agrupe por index\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "eRrHD1w4VdB4"
   },
   "outputs": [],
   "source": [
    "image_height = 224 #Defina o tamanho  da imagem\n",
    "image_width = 224 #Defina a largura da iamge\n",
    "from keras.preprocessing.image import load_img #carrega funcao para carraegar imagem\n",
    "from keras.preprocessing.image import img_to_array #carrega funcao para converter imagem para array\n",
    "\n",
    "#Funcao que remove quebra de linha\n",
    "def remove_spaces(cell):  \n",
    "    return cell.replace('\\n',' ')\n",
    "\n",
    "#Converte que carrega a image e depois convertte para array\n",
    "def get_array(image_path):\n",
    "    #img = load_img(image_path, target_size=(image_height, image_width), color_mode='grayscale')\n",
    "    img = load_img(\"D:/SiDi/Project/Modulo II/dataset/b-t4sa_imgs\" + '/' + image_path, target_size=(image_height, image_width), color_mode='grayscale')\n",
    "\n",
    "    return img_to_array(img)\n",
    "\n",
    "def get_array_colab(image_path):\n",
    "    image_path= os.getcwd() + '/'+ image_path\n",
    "    img = load_img(image_path, target_size=(image_height, image_width), color_mode='grayscale')\n",
    "    return img_to_array(img)\n",
    "\n",
    "#Mapeaa os tipos de classes existente nos rotulos de predicoes\n",
    "def to_one_hot(y, class_mapping, num_classes):\n",
    "    y_int = y.map(class_mapping)\n",
    "    return to_categorical(y_int, num_classes)\n",
    "\n",
    "#X_text = df['text'].apply(remove_spaces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Numero de classes do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "fdL7BAx0VdB5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NEG': 0, 'NEU': 1, 'POS': 2}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = df['sent_text'].nunique()\n",
    "#Faz o mapeeamento da classe com o id\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['sent_text']))}\n",
    "print(class_mapping)\n",
    "#y_int = df['sent_text'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "jCbAzR3KVdB5"
   },
   "outputs": [],
   "source": [
    "docs = {}\n",
    "\n",
    "values = df['image_name'].value_counts()[0:100] #Identificador da imagem para agrupamento\n",
    "for i in values.index:\n",
    "    docs[i] = df[df['image_name'] == i].sort_values(by=['image_name'])#adicionar numa lista de documentos no chave valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "xWwrVJ8WaJL5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'768097808037605376-1'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['image_name'][0])\n",
    "df['image_name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "9WIkvJ_1VdB6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "X_keys = [key for key in docs.keys()]#Iterar sobre cada documento apenas com a chave\n",
    "\n",
    "train_size = int(len(X_keys)*0.70)#Divide em teste e e validação\n",
    "print(len(X_keys[:train_size]))\n",
    "print(len(X_keys[train_size:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Um_fzjB7SkVp"
   },
   "outputs": [],
   "source": [
    "X_train_text = []\n",
    "X_train_image = []\n",
    "y_train = []\n",
    "image_path = []\n",
    "y_total = []\n",
    "img_total = []\n",
    "text_total = []\n",
    "page_total = []\n",
    "doc_total = []\n",
    "target_total = []\n",
    "\n",
    "for i in X_keys[:train_size]:\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot(docs[i]['sent_text'], class_mapping, num_classes)\n",
    "    \n",
    "    text_image = pd.concat([X_image, X_text], axis=1)\n",
    "    \n",
    "    image_path.extend(docs[i]['image_path'])\n",
    "    X_train_text.extend(X_text)\n",
    "    X_train_image.extend(X_image)\n",
    "    y_train.extend(y)\n",
    "    y_total.append(y)\n",
    "    text_total.append(X_text)\n",
    "    img_total.append(X_image)\n",
    "    page_total.append(docs[i]['image_name'])\n",
    "    doc_total.append(docs[i]['image_name'])\n",
    "    target_total.append(docs[i]['sent_text'])\n",
    "    \n",
    "    \n",
    "    \n",
    "X_train_text = pd.Series(X_train_text)\n",
    "X_train_image = pd.Series(X_train_image)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "5xZJ6a_QSkVp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rbsa2\\AppData\\Local\\Temp/ipykernel_19260/818595839.py:23: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  X_test_text = pd.Series(X_test_text)\n",
      "C:\\Users\\rbsa2\\AppData\\Local\\Temp/ipykernel_19260/818595839.py:24: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  X_test_image = pd.Series(X_test_image)\n"
     ]
    }
   ],
   "source": [
    "X_test_text = []\n",
    "X_test_image = []\n",
    "y_test = []\n",
    "\n",
    "for i in X_keys[train_size:train_size]:\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot(docs[i]['sent_text'], class_mapping, num_classes)\n",
    "    \n",
    "    text_image = pd.concat([X_image, X_text], axis=1)\n",
    "    \n",
    "    X_test_text.extend(X_text)\n",
    "    X_test_image.extend(X_image)\n",
    "    y_test.extend(y)\n",
    "    y_total.append(y)\n",
    "    text_total.append(X_text)\n",
    "    img_total.append(X_image)\n",
    "    page_total.append(docs[i]['image_name'])\n",
    "    doc_total.append(docs[i]['image_name'])\n",
    "    target_total.append(docs[i]['sent_text'])\n",
    "    \n",
    "    \n",
    "X_test_text = pd.Series(X_test_text)\n",
    "X_test_image = pd.Series(X_test_image)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "hnxQmZqfL8Dx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_total)\n",
    "len(text_total)\n",
    "len(img_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Bnv7uJgJonK1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0    768097808037605376-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313732    784211850053488641-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313730    784211829098680320-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313729    784211770370129920-4\n",
       "  Name: image_name, dtype: object,\n",
       "  313728    784211770370129920-3\n",
       "  Name: image_name, dtype: object,\n",
       "  313727    784211770370129920-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313726    784211770370129920-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313725    784211766158954500-4\n",
       "  Name: image_name, dtype: object,\n",
       "  313724    784211766158954500-3\n",
       "  Name: image_name, dtype: object,\n",
       "  313723    784211766158954500-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313722    784211766158954500-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313721    784211753567649793-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313720    784211749411184640-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313719    784211745195823105-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313718    784211736819699712-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313717    784211736807124992-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313716    784211728401854464-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313715    784211724232720384-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313714    784211724232687620-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313713    784211711637106689-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313712    784211686483984384-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313711    784211669685706752-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313710    784211665491402756-3\n",
       "  Name: image_name, dtype: object,\n",
       "  313709    784211665491402756-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313708    784211661305421824-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313707    784211636144013312-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313706    784211539683319808-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313731    784211845842362370-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313733    784211887823085572-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313761    784212349192433664-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313734    784211904566796288-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313759    784212290463727616-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313758    784212244305436672-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313757    784212219168952321-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313756    784212202370666497-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313755    784212202370666496-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313754    784212198197460993-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313753    784212177200615424-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313752    784212168837328896-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313751    784212168832978945-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313750    784212160432013312-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313749    784212105901793280-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313748    784212093339860992-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313747    784212068157100035-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313746    784212063983894528-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313745    784212063958728704-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313744    784212059764449280-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313743    784212047185653760-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313742    784212047177416704-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313741    784212043008180225-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313740    784212038797123585-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313739    784211946530824192-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313738    784211946518315008-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313737    784211921377439744-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313736    784211921352347649-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313735    784211904575209473-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313705    784211531273646080-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313704    784211497731883008-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313703    784211485169823744-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313702    784211459987374082-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313673    784210705004105728-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313672    784210688231153664-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313671    784210667272343552-3\n",
       "  Name: image_name, dtype: object,\n",
       "  313670    784210667272343552-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313669    784210667272343552-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313668    784210579191803904-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313667    784210541417947136-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313666    784210495284899840-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313665    784210491086368768-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313664    784210398832652288-1\n",
       "  Name: image_name, dtype: object],\n",
       " [0    768097808037605376-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313732    784211850053488641-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313730    784211829098680320-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313729    784211770370129920-4\n",
       "  Name: image_name, dtype: object,\n",
       "  313728    784211770370129920-3\n",
       "  Name: image_name, dtype: object,\n",
       "  313727    784211770370129920-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313726    784211770370129920-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313725    784211766158954500-4\n",
       "  Name: image_name, dtype: object,\n",
       "  313724    784211766158954500-3\n",
       "  Name: image_name, dtype: object,\n",
       "  313723    784211766158954500-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313722    784211766158954500-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313721    784211753567649793-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313720    784211749411184640-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313719    784211745195823105-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313718    784211736819699712-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313717    784211736807124992-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313716    784211728401854464-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313715    784211724232720384-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313714    784211724232687620-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313713    784211711637106689-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313712    784211686483984384-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313711    784211669685706752-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313710    784211665491402756-3\n",
       "  Name: image_name, dtype: object,\n",
       "  313709    784211665491402756-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313708    784211661305421824-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313707    784211636144013312-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313706    784211539683319808-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313731    784211845842362370-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313733    784211887823085572-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313761    784212349192433664-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313734    784211904566796288-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313759    784212290463727616-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313758    784212244305436672-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313757    784212219168952321-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313756    784212202370666497-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313755    784212202370666496-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313754    784212198197460993-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313753    784212177200615424-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313752    784212168837328896-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313751    784212168832978945-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313750    784212160432013312-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313749    784212105901793280-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313748    784212093339860992-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313747    784212068157100035-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313746    784212063983894528-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313745    784212063958728704-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313744    784212059764449280-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313743    784212047185653760-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313742    784212047177416704-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313741    784212043008180225-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313740    784212038797123585-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313739    784211946530824192-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313738    784211946518315008-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313737    784211921377439744-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313736    784211921352347649-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313735    784211904575209473-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313705    784211531273646080-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313704    784211497731883008-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313703    784211485169823744-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313702    784211459987374082-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313673    784210705004105728-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313672    784210688231153664-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313671    784210667272343552-3\n",
       "  Name: image_name, dtype: object,\n",
       "  313670    784210667272343552-2\n",
       "  Name: image_name, dtype: object,\n",
       "  313669    784210667272343552-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313668    784210579191803904-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313667    784210541417947136-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313666    784210495284899840-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313665    784210491086368768-1\n",
       "  Name: image_name, dtype: object,\n",
       "  313664    784210398832652288-1\n",
       "  Name: image_name, dtype: object])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_total, page_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Qj8Os0Mgh7k1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "oj-rAfeilKpY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEG': 0, 'NEU': 1, 'POS': 2}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "IaNqdSBhTotu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list  \n",
    "real_mapping_class = []\n",
    "for x in y_total:\n",
    "  for z in x:\n",
    "    real_mapping_class.append(z)\n",
    "\n",
    "\n",
    "print(len(real_mapping_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "MguaH0tyqjom"
   },
   "outputs": [],
   "source": [
    "list  \n",
    "real_mapping_class = []\n",
    "doc_order = []\n",
    "page_order = []\n",
    "target_order = []\n",
    "for doc_group, page_group, target_group in  zip(doc_total,page_total,target_total):\n",
    "  for doc, page, target in zip(doc_group, page_group, target_group):\n",
    "    doc_order.append(doc)\n",
    "    page_order.append(page)\n",
    "    target_order.append(target)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "lQu4UMRjsRSg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70, 70)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_order), len(page_order), len(target_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "7dbi2vmascJ-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('768097808037605376-1', '768097808037605376-1', 'NEG')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_order[0], page_order[0], target_order[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "fBVLGJE1sjxa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('784210398832652288-1', '784210398832652288-1', 'NEG')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_order[-1], page_order[-1], target_order[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IfAjT11aFT0"
   },
   "source": [
    "# Join Train and Test (Test and Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "XRxLzx9RNC_J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_join_text = X_train_text.append(X_test_text)\n",
    "X_join_image = X_train_image.append(X_test_image)\n",
    "len(X_join_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be4vTzpm6tx5"
   },
   "source": [
    "# Carrega Dados para Validacao ou Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Skh1Ums27mow"
   },
   "source": [
    "# Carrega objeto de Dados para servir de entrada na rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "M1JOg-1rVdB8"
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    \"\"\"\n",
    "    Class to handle loading and processing of raw datasets.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_source,\n",
    "                 alphabet=\" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\",\n",
    "                 input_size=1014, num_of_classes=3, alphabet_size=71):\n",
    "        \"\"\"\n",
    "        Initialization of a Data object.\n",
    "\n",
    "        Args:\n",
    "            data_source (str): Raw data file path\n",
    "            alphabet (str): Alphabet of characters to index\n",
    "            input_size (int): Size of input features\n",
    "            num_of_classes (int): Number of classes in data\n",
    "        \"\"\"\n",
    "        self.alphabet = alphabet\n",
    "        self.alphabet_size = len(self.alphabet)\n",
    "        self.dict = {}  # Maps each character to an integer\n",
    "        self.no_of_classes = num_of_classes\n",
    "        for idx, char in enumerate(self.alphabet):\n",
    "            self.dict[char] = idx + 1\n",
    "        self.length = input_size\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load raw data from the source file into data variable.\n",
    "\n",
    "        Returns: None\n",
    "\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for doc in self.data_source:\n",
    "            data.append(doc)\n",
    "        self.data = np.array(data)\n",
    "\n",
    "    def get_all_data(self):\n",
    "        \"\"\"\n",
    "        Return all loaded data from data variable.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray) Data transformed from raw to indexed form with associated one-hot label.\n",
    "\n",
    "        \"\"\"\n",
    "        data_size = len(self.data)\n",
    "        start_index = 0\n",
    "        end_index = data_size\n",
    "        batch_texts = self.data[start_index:end_index]\n",
    "        batch_indices = []\n",
    "        one_hot = np.eye(self.no_of_classes, dtype='int64')\n",
    "        classes = []\n",
    "        for c, s in batch_texts:\n",
    "            batch_indices.append(self.str_to_indexes(s))\n",
    "            c = int(c) - 1\n",
    "            classes.append(one_hot[c])\n",
    "        return np.asarray(batch_indices, dtype='int64'), np.asarray(classes)\n",
    "\n",
    "    def str_to_indexes(self, s):\n",
    "        \"\"\"\n",
    "        Convert a string to character indexes based on character dictionary.\n",
    "        \n",
    "        Args:\n",
    "            s (str): String to be converted to indexes\n",
    "\n",
    "        Returns:\n",
    "            str2idx (np.ndarray): Indexes of characters in s\n",
    "\n",
    "        \"\"\"\n",
    "        s = s.lower()\n",
    "        max_length = min(len(s), self.length)\n",
    "        str2idx = np.zeros(self.length, dtype='int64')\n",
    "        for i in range(1, max_length + 1):\n",
    "            c = s[-i]\n",
    "            if c in self.dict:\n",
    "                str2idx[i - 1] = self.dict[c]\n",
    "        return str2idx\n",
    "\n",
    "    def vectorize_sentences(self, data, char_indices):\n",
    "        X = []\n",
    "\n",
    "        for doc in data:\n",
    "        \n",
    "            x = [char_indices[w] if w in self.alphabet else 0 for w in doc.lower()]\n",
    "            x2 = np.eye(self.alphabet_size + 1)[x]\n",
    "            X.append(x2)\n",
    "            \n",
    "        return pad_sequences(X, maxlen=self.length, padding=\"pre\")\n",
    "\n",
    "    def get_target_data(self):\n",
    "        \"\"\"\n",
    "        Return all loaded data from data variable.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray) Data transformed from raw to indexed form with associated one-hot label.\n",
    "\n",
    "        \"\"\"\n",
    "        data_size = len(self.data)\n",
    "        start_index = 0\n",
    "        end_index = data_size\n",
    "        batch_texts = self.data[start_index:end_index]\n",
    "        batch_indices = []\n",
    "        one_hot = np.eye(self.no_of_classes, dtype='int64')\n",
    "        classes = []\n",
    "        for c, s in batch_texts:\n",
    "            c = int(c)\n",
    "            classes.append(one_hot[c])\n",
    "        return np.asarray(classes)\n",
    "\n",
    "    def get_data_3dim(self):\n",
    "        '''\n",
    "        transform training input to shape Number_of_Rows X MaxLen X Alphabet_size\n",
    "        this is need to be done to avoid the use of embedding layer, wich is not supported on the Tflite converter\n",
    "        '''\n",
    "        char_indices = dict((c, i) for i, c in enumerate(self.alphabet,1))\n",
    "        indices_char = dict((i, c) for i, c in enumerate(self.alphabet,1))\n",
    "\n",
    "        \n",
    "        train_data = self.vectorize_sentences(self.data, char_indices)\n",
    "        train_data.shape\n",
    "        return train_data\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcL2G6LK8s1F"
   },
   "source": [
    "# Instancia os Objetos (Data) Treinamento e Validacao a partir do  conjunto de dados Treinamento e Validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "njYtvIfTVdB8"
   },
   "outputs": [],
   "source": [
    "training_data = Data(data_source=X_train_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "training_data.load_data()\n",
    "\n",
    "validation_data = Data(data_source=X_test_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "validation_data.load_data()\n",
    "    \n",
    "\n",
    "X_train_text = training_data.get_data_3dim()\n",
    "X_test_text = validation_data.get_data_3dim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JsPJ43B9QUP"
   },
   "source": [
    "#Converte de Imagem para Array Numpy - image_to_numpy(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "tVUP1aAPVdB9"
   },
   "outputs": [],
   "source": [
    "def image_to_numpy(image_df):\n",
    "    all_images = []\n",
    "    for i in range(len(image_df)):\n",
    "        all_images.append(image_df.iloc[i])  \n",
    "    return np.array(all_images)\n",
    "\n",
    "X_train_image = image_to_numpy(X_train_image)\n",
    "X_test_image = image_to_numpy(X_test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "nf2VBXRxD_An"
   },
   "outputs": [],
   "source": [
    "merge_data = Data(data_source=X_join_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "merge_data.load_data()\n",
    "    \n",
    "\n",
    "X_join_text = merge_data.get_data_3dim()\n",
    "\n",
    "X_join_image = image_to_numpy(X_join_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ijk7PaQB9hTt"
   },
   "source": [
    "#Imprime o Shape do Objeto de Treinamento Convertido Array Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Ljs8GVLVVdB9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssjgpvFe91Wg"
   },
   "source": [
    "# (01) - Conjunto de Dados de Validacao - Declara a Classe ImageValidationCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oW8DDL5zVdB9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 224, 224, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 217, 217, 32)      2080      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 36, 36, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 31, 31, 32)        36896     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " encoded_image (Dense)       (None, 256)               205056    \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 244,803\n",
      "Trainable params: 244,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SiDi\\Project\\Modulo II\\github\\keras-tf-gpu\\keras-tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "def predict(model, X_test_image, batch_size=32):\n",
    "    y_predict = np.round(model.predict(X_test_image))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class ImageValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_image,y_test, metric = 'kappa'):\n",
    "        self.X_test_image = X_test_image\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, X_test_image)\n",
    "        #true_labels = [label2Idx[x[1]] for x in self.test_data]\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metric)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)\n",
    "\n",
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(32, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='tanh', name='encoded_image')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_image)\n",
    "model_image = Model(image_input, output)\n",
    "model_image.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "print(model_image.summary())\n",
    "\n",
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = ImageValidationCheckpoint(model_file, X_test_image, y_test, metric=optimize_for)\n",
    "    model_image.fit(X_train_image, y_train, epochs=40, batch_size=32,\n",
    "                     validation_data=(X_test_image, y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_image.save('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEQeKf8hAGTJ"
   },
   "source": [
    "# (01) - Configuracao da Arquitetura I \n",
    "\n",
    "1.   Conv2D -> Inicial(32 (8,8)) e Oculta (32 (6,6))\n",
    "2.   MaxPooling -> (32 (6,6))\n",
    "3.   Loss -> categorical_crossentropy   \n",
    "4.   optimizer -> optimizers.RMSprop(lr=1e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOcZeNhu_h3R"
   },
   "outputs": [],
   "source": [
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(32, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(32, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='tanh', name='encoded_image')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_image)\n",
    "model_image = Model(image_input, output)\n",
    "model_image.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "print(model_image.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHf7mf8gB3En"
   },
   "source": [
    "# (01) - Avaliacao da Arquitetura I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCL1J9q9Bmga"
   },
   "outputs": [],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = ImageValidationCheckpoint(model_file, X_test_image, y_test, metric=optimize_for)\n",
    "    model_image.fit(X_train_image, y_train, epochs=40, batch_size=32,\n",
    "                     validation_data=(X_test_image, y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_image.save('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuWVpNqrCL22"
   },
   "source": [
    "# (02) - Conjunto de Dados de Validacao Declara a Classe ImageValidationCheckpoint \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MonFCIzTVdB-"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_test_image, batch_size=32):\n",
    "    y_predict = np.round(model.predict(X_test_image))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class ImageValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_image,y_test, metric = 'kappa'):\n",
    "        self.X_test_image = X_test_image\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, X_test_image)\n",
    "        #true_labels = [label2Idx[x[1]] for x in self.test_data]\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            #'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metrics)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiW3iTc2CcGY"
   },
   "source": [
    "# (02) - Configuracao da Arquitetura II\n",
    "\n",
    "\n",
    "1.   Conv2D -> Inicial(16,(8,8)) e Oculta (16,(6, 6))\n",
    "2.   MaxPooling -> (6,6)\n",
    "3.   Loss -> categorical_crossentropy   \n",
    "4.   optimizer -> optimizers.RMSprop(lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UP6_lJFCZpO"
   },
   "outputs": [],
   "source": [
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(16, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='tanh', name='encoded_image')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_image)\n",
    "model_image = Model(image_input, output)\n",
    "model_image.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "print(model_image.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTUc6EsHN77K"
   },
   "source": [
    "# (02) - Avaliacao da Arquitetura II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfoSeydlVdB_"
   },
   "outputs": [],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = ImageValidationCheckpoint(model_file, X_test_image, y_test, metric=optimize_for)\n",
    "    model_image.fit(X_train_image, y_train, epochs=40, batch_size=16,\n",
    "                     validation_data=(X_test_image, y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_image.save('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIG409EYP5rt"
   },
   "source": [
    "# Teste o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTSdtUDqVdB_"
   },
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_image.predict(X_test_image)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAOCHOr3QL-U"
   },
   "source": [
    "# Exporte o modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RP51R_dVdCA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( checkpoint.history, open( \"image-model-aibox40.pickle\", \"wb\" ) )\n",
    "print(checkpoint.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77vZRztnVdCA"
   },
   "outputs": [],
   "source": [
    "print(avg_result)\n",
    "print(avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzyoaPAXyNIz"
   },
   "source": [
    "# (03) - Conjunto de Dados de Validacao Declara a Classe ImageValidationCheckpoint \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpxgPeiEVdCA"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_test_text, batch_size=32):\n",
    "    y_predict = np.round(model.predict(X_test_text))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class TextValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_text,y_test, metric = 'kappa'):\n",
    "        self.X_test_text = X_test_text\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, self.X_test_text)\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            #'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metrics)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7m7kuUiyV73"
   },
   "source": [
    "# (03) - Configuracao da Arquitetura II\n",
    "\n",
    "\n",
    "1.   Conv2D -> Inicial(16,(8,8)) e Oculta (16,(6, 6))\n",
    "2.   MaxPooling -> (6,6)\n",
    "3.   Loss -> categorical_crossentropy   \n",
    "4.   optimizer -> optimizers.RMSprop(lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ua-FGoCtygdK"
   },
   "outputs": [],
   "source": [
    "text_input = Input(shape=(input_size, alphabet_size), name='text_input', dtype='float32')\n",
    "\n",
    "x = Convolution1D(nb_filter=50, filter_length=3,\n",
    "                     border_mode='valid', activation='tanh',\n",
    "                     input_shape=(input_size, alphabet_size))(text_input)\n",
    "\n",
    "for cl in conv_layers:\n",
    "    x = Convolution1D(cl[0], cl[1])(x)\n",
    "    #x = ThresholdedReLU(threshold)(x)\n",
    "    if cl[2] != -1:\n",
    "        x = MaxPooling1D(cl[2])(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for fl in fully_connected_layers:\n",
    "    x = Dense(fl)(x)\n",
    "    #x = ThresholdedReLU(threshold)(x)\n",
    "    x = Dropout(dropout_p)(x)\n",
    "\n",
    "encoded_text = Dense(256, activation='tanh', name='encoded_text')(x)\n",
    "\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(encoded_text)\n",
    "model_text = Model(text_input, output)\n",
    "model_text.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "print(model_text.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C6Wsc_Cymvg"
   },
   "source": [
    "# (03) - Treino da Rede Neural da Arquitetura III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxJJyKEPVdCA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = TextValidationCheckpoint(model_file, X_test_text, y_test, metric=optimize_for)\n",
    "    model_text.fit(X_train_text, y_train, epochs=40, batch_size=16,\n",
    "                     validation_data=(X_test_text, y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_text.save('model_ness_txt_image_v1.h5')\n",
    "\n",
    "model_text.save('model_ness_txt_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCPVTFx1zf2y"
   },
   "source": [
    "# (03) Avaliação da Rede Neural III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpNfCXAnVdCB"
   },
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_text.predict(X_test_text)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3IjxHmrzpp3"
   },
   "source": [
    "# (03) Exportação do Modelo da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IW_JdzNuVdCB"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( checkpoint.history, open( \"text-model-aibox40.pickle\", \"wb\" ) )\n",
    "print(checkpoint.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCWRUDEqzxTM"
   },
   "source": [
    "# (04) - Conjunto de Dados de Validacao Declara a Classe ImageValidationCheckpoint \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jb96kKeGVdCB"
   },
   "outputs": [],
   "source": [
    "def predict(model, X_test_text, X_test_image, batch_size=32):\n",
    "    y_predict = np.round(model.predict([X_test_text, X_test_image]))\n",
    "    return y_predict\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "class ValidationCheckpoint(Callback):\n",
    "    def __init__(self, filepath, X_test_text, X_test_image,y_test, metric = 'kappa'):\n",
    "        self.X_test_text = X_test_text\n",
    "        self.X_test_image = X_test_image\n",
    "        self.y_test = y_test\n",
    "        self.metric = metric\n",
    "        self.max_metric = float('-inf')\n",
    "        self.max_metrics = None\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        predicted_labels = predict(self.model, self.X_test_text, X_test_image)\n",
    "        #true_labels = [label2Idx[x[1]] for x in self.test_data]\n",
    "        true_labels = one_hot_decode(self.y_test)\n",
    "        predicted_labels = one_hot_decode(predicted_labels)\n",
    "        eval_metrics = {\n",
    "            'accuracy' : sklm.accuracy_score(true_labels, predicted_labels),\n",
    "            'f1_micro' : sklm.f1_score(true_labels, predicted_labels, average='micro'),\n",
    "            'f1_macro' : sklm.f1_score(true_labels, predicted_labels, average='macro'),\n",
    "            #'f1_binary' : sklm.f1_score(true_labels, predicted_labels, average='weighted', pos_label = 1),\n",
    "            'kappa' : sklm.cohen_kappa_score(true_labels, predicted_labels)\n",
    "        }\n",
    "        eval_metric = eval_metrics[self.metric]\n",
    "        self.history.append(eval_metrics)\n",
    "        \n",
    "        if epoch > -1 and eval_metric > self.max_metric:\n",
    "            print(\"\\n\" + self.metric + \" improvement: \" + str(eval_metric) + \" (before: \" + str(self.max_metric) + \"), saving to \" + self.filepath)\n",
    "            self.max_metric = eval_metric     # optimization target\n",
    "            self.max_metrics = eval_metrics   # all metrics\n",
    "            #self.model.save(self.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnjWJgPj3MH2"
   },
   "source": [
    "# (04) Configuração da Arquitetura (Imagem + Texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zX8rleYm3V4g"
   },
   "outputs": [],
   "source": [
    "image_input = Input(shape=(image_height, image_width, 1), name='image_input', dtype='float32')\n",
    "x = layers.Conv2D(16, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (8, 8), activation='tanh',input_shape=(image_height, image_width, 1))(image_input)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Conv2D(16, (6, 6), activation='tanh')(x)\n",
    "x = layers.MaxPooling2D((6, 6))(x)\n",
    "x = layers.Flatten()(x)\n",
    "encoded_image = layers.Dense(256, activation='tanh', name='encoded_image')(x)\n",
    "\n",
    "\n",
    "\n",
    "text_input = Input(shape=(input_size, alphabet_size), name='text_input', dtype='float32')\n",
    "\n",
    "x = Convolution1D(nb_filter=50, filter_length=3,\n",
    "                     border_mode='valid', activation='tanh',\n",
    "                     input_shape=(input_size, alphabet_size))(text_input)\n",
    "\n",
    "for cl in conv_layers:\n",
    "    x = Convolution1D(cl[0], cl[1])(x)\n",
    "    #x = ThresholdedReLU(threshold)(x)\n",
    "    if cl[2] != -1:\n",
    "        x = MaxPooling1D(cl[2])(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for fl in fully_connected_layers:\n",
    "    x = Dense(fl)(x)\n",
    "    #x = ThresholdedReLU(threshold)(x)\n",
    "    x = Dropout(dropout_p)(x)\n",
    "\n",
    "encoded_text = Dense(256, activation='tanh', name='encoded_text')(x)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_image], axis=-1, name='concatanated')\n",
    "output = layers.Dense(num_classes, activation='softmax', name='output')(concatenated)\n",
    "model_hybrid = Model([text_input, image_input], output)\n",
    "model_hybrid.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "model_hybrid.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6y-UNhs35Jd"
   },
   "source": [
    "# (04) - Treinamento da Rede Neural = Texto e Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seXwiuVqVdCC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_repeats = 1\n",
    "exp_history = []\n",
    "optimize_for = 'kappa'\n",
    "model_file = 'model_ness_txt_image_v1_test.h5'\n",
    "for i in range(n_repeats):\n",
    "    checkpoint = ValidationCheckpoint(model_file, X_test_text, X_test_image, y_test, metric=optimize_for)\n",
    "    model_hybrid.fit([X_train_text, X_train_image], y_train, epochs=40, batch_size=32,\n",
    "                     validation_data=([X_test_text, X_test_image], y_test)\n",
    "                     ,callbacks = [checkpoint])\n",
    "    exp_history.append(checkpoint.max_metrics)\n",
    "    \n",
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)\n",
    "model_hybrid.save('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7_XAAcT49RZ"
   },
   "source": [
    "# (04)  Exportação Modelo da Rede Neural ( Texto & Imagem )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9a_mHV4VdCC"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( checkpoint.history, open( \"text-image-model-aibox40.pickle\", \"wb\" ) )\n",
    "print(checkpoint.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACuipGVW5Dcg"
   },
   "source": [
    "# 04 Single Page Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eaqcr-vMVdCD"
   },
   "outputs": [],
   "source": [
    "avg_result = sum([m['kappa'] for m in exp_history]) / n_repeats\n",
    "avg_acc = sum([m['accuracy'] for m in exp_history]) / n_repeats\n",
    "print(avg_result)\n",
    "print(avg_acc)\n",
    "for i, r in enumerate(exp_history):\n",
    "    model_file = \"ness_exp1_single-page_repeat-%02d.hdf5\" % (i,)\n",
    "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_macro']) + ' ' + model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOzWXFfS5XBl"
   },
   "source": [
    "#(04) Recarrega Modelo Hibrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WD-7fRQaVdCD"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_hybrid = load_model('model_ness_txt_image_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcMeIPJm5imp"
   },
   "source": [
    "# (04) Avalia modelo Hibrido (Texto & Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYU39etIVdCD"
   },
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_hybrid.predict([X_test_text, X_test_image])\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bksymW4qNvrL"
   },
   "outputs": [],
   "source": [
    "#X_join_text = X_train_text.append(X_test_text)\n",
    "#X_image = X_train_image.append(X_test_image)\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApW806-tZHfM"
   },
   "source": [
    "# Fase de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpcPXV7FZFb8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "y_pred = model_hybrid.predict([X_join_text, X_join_image])\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAw1DmFPuREU"
   },
   "source": [
    "# Mapping Id of Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuDlLakynaAo"
   },
   "outputs": [],
   "source": [
    "id_class_mapping = {idx:label for idx,label in enumerate(np.unique(df['sent_text']))}\n",
    "id_class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3M86pz8ZvVsl"
   },
   "outputs": [],
   "source": [
    "pred_class = []\n",
    "for i in range(len(y_pred)):\n",
    "  pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "  pred_class.append(id_class_mapping[pred[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HOcAUz1watX"
   },
   "source": [
    "# To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suuDHSCQwclR"
   },
   "outputs": [],
   "source": [
    "df_seq = pd.DataFrame({'image_name': doc_order, 'image_page': page_order, 'sent_text': target_order, 'image_predict': pred_class})\n",
    "\n",
    "df_seq.to_csv('sequence-classifier-output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-n_rP8zh7I7z"
   },
   "outputs": [],
   "source": [
    "df_seq['match'] = np.where(df_seq['sent_text']==df_seq['image_predict'], \n",
    "                                           'yes', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QOmRMkq75Ff"
   },
   "outputs": [],
   "source": [
    "df_seq['match'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRERUqTK9Wa5"
   },
   "outputs": [],
   "source": [
    "df_seq.head(n=2970)[-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8lWsxakBkuq"
   },
   "outputs": [],
   "source": [
    "df_seq['match'].apply(lambda x: x == 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ObWteqn-mTP"
   },
   "outputs": [],
   "source": [
    "df_seq[df_seq['match'].apply(lambda x: x == 'no')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzaa9B1tZPCa"
   },
   "source": [
    "# Mapping Real Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMY4G_qLZFcA"
   },
   "outputs": [],
   "source": [
    "y_real = np.array(real_mapping_class)\n",
    "\n",
    "real_mapping_class_seq = []\n",
    "for i in range(len(y_real)):\n",
    "  pred = np.where(y_real[i] == np.amax(y_real[i]))\n",
    "  real_mapping_class_seq.append(pred[0][0])\n",
    "  #print(pred[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQM0R8_HiZz1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72jTmi8ZZbb4"
   },
   "source": [
    "# Mapping Pred Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocktA3u9ZFcB"
   },
   "outputs": [],
   "source": [
    "pred_mapping_class = []\n",
    "for i in range(len(y_pred)):\n",
    "  pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "  pred_mapping_class.append(pred[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o22xZKIZZnMj"
   },
   "source": [
    "# Export Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kzgH6PIZFcB"
   },
   "outputs": [],
   "source": [
    "df['real_map_class'] = real_mapping_class_seq\n",
    "df['pred_map_class'] = pred_mapping_class\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv('ness-seq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJVntxnhZ6WP"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pw6ZPeq76RB"
   },
   "source": [
    "#04 Realiza o mapeamento da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2P5Reb_VdCD"
   },
   "outputs": [],
   "source": [
    "num_classes = df['sent_text'].nunique()\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['sent_text']))}\n",
    "y_int = df['sent_text'].map(class_mapping)\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgRhU8wbZ3dI"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvqttvg58I7v"
   },
   "source": [
    "# Verifica a taxa de acertos com classe predita e classe esperada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EFj2QBBVdCD"
   },
   "outputs": [],
   "source": [
    "y_f = []\n",
    "for i in range(len(y_pred)):\n",
    "    pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "    y_f.append(pred[0][0])\n",
    "\n",
    "print(classification_report(Y_test, y_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eL5wgZpxVdCD"
   },
   "outputs": [],
   "source": [
    "{'anexo': 0, 'anotacao': 1, 'autos': 2, 'branco': 3, 'certidao': 4, \n",
    " 'citacao': 5, 'decisao': 6, 'intimacao': 7, 'jec': 8, 'lixo': 9, 'movimentacao': 10, \n",
    " 'peticao': 11, 'procuracao': 12, 'setenca': 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gF8dS_6Fi3vM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTeaVqCc8aoq"
   },
   "source": [
    "#Prediz com a base de treimaneto texto e image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXBAxnsHVdCE"
   },
   "outputs": [],
   "source": [
    "y_pred = model_hybrid.predict([X_train_text, X_train_image])\n",
    "y_f = []\n",
    "Y_train = np.argmax(y_train, axis=1) # Convert one-hot to index\n",
    "for i in range(len(y_pred)):\n",
    "    pred = np.where(y_pred[i] == np.amax(y_pred[i]))\n",
    "    y_f.append(pred[0][0])\n",
    "\n",
    "print(classification_report(Y_train, y_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aXjq_1NVdCE"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "lens = []\n",
    "for key in X_keys[:train_size]:\n",
    "    X.append([[class_mapping[i]] for i in list(docs[key]['sent_text'])])\n",
    "    lens.append(len(X[-1]))\n",
    "X_train = np.concatenate(X)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmJ_t5PKVdCE"
   },
   "outputs": [],
   "source": [
    "## OS EXPERIMENTOS ACABAM AQUI, EMBAIXO APENAS TESTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZxoLaH7VdCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Eur_KVMVdCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YL4BsT0fVdCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3PxjKpwVdCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WrJJS2AVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_x7ug-YxVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0qxDy0SVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pqy8xuEVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZp3ARymVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XISJ73vVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENVgmp4QVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUU-_QIbVdCF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULbWYABRVdCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyhjXtpWVdCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpA-DtzTVdCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBGx_VIQVdCG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQ8kZTJBVdCG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn.hmm import MultinomialHMM\n",
    "\n",
    "h = MultinomialHMM(n_components=12)\n",
    "h.fit(X_train, lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO4NItvtVdCG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_hmm_pp_test = []\n",
    "y_hmm_test = []\n",
    "y_test_true_hmm = []\n",
    "for i in X_keys[train_size:]:\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot(docs[i]['sent_text'], class_mapping, num_classes)\n",
    "    \n",
    "    X_test_image = image_to_numpy(X_image)\n",
    "    test_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    test_data.load_data()\n",
    "\n",
    "\n",
    "    X_test_text = test_data.get_data_3dim()\n",
    "\n",
    "    \n",
    "    X_hmm_test = model_hybrid.predict([X_test_text, X_test_image])\n",
    "    \n",
    "    results_to_int  = np.argmax(X_hmm_test, axis=1)\n",
    "    y_hmm = h.decode(results_to_int.reshape(-1,1))\n",
    "    y_hmm_test.extend(y_hmm[1])\n",
    "    y_int = docs[i]['sent_text'].map(class_mapping)\n",
    "    y_test_true_hmm.extend(y_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Sqg5vESVdCG"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_true_hmm, y_hmm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJYStsC8VdCG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = df['sent_text'].nunique()\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['sent_text']))}\n",
    "print(class_mapping)\n",
    "for i in range(len(docs['j3'])):\n",
    "    print(class_mapping[docs['j3']['sent_text'].iloc[i]], c[1][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FGSgt4sVdCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beoq-va_VdCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfDeuTjDVdCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otjoE6v4VdCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSQYc6dKVdCH"
   },
   "outputs": [],
   "source": [
    "from attention_decoder import AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-1xEoCGVdCH"
   },
   "outputs": [],
   "source": [
    "\n",
    "def temporalize(X, y, lookback):\n",
    "    output_X = []\n",
    "    output_y = []\n",
    "    for i in range(len(X)-lookback-1):\n",
    "        t = []\n",
    "        for j in range(1,lookback+1):\n",
    "            # Gather past records upto the lookback period\n",
    "            t.append(X[[(i+j+1)], :])\n",
    "        output_X.append(t)\n",
    "    return output_X, y\n",
    "\n",
    "def get_lstm_model_with_attention(num_classes, timesteps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(timesteps, num_classes), return_sequences=True))\n",
    "    model.add(LSTM(100, input_shape=(timesteps, num_classes), return_sequences=True))\n",
    "    model.add(LSTM(100, input_shape=(timesteps, num_classes), return_sequences=True))\n",
    "    model.add(AttentionDecoder(100, num_classes))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "    return model\n",
    "def get_lstm_model_simple_reconstructor(num_classes, timesteps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='relu', input_shape=(timesteps,num_classes), return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(num_classes)))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_lstm_model_autoencoder(num_classes, timesteps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='relu', input_shape=(timesteps,num_classes), return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "    model.add(RepeatVector(timesteps))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(num_classes)))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def treinar_lstm_ac(X,y, timesteps, num_classes, model_lstm):\n",
    "    \n",
    "    X_train, y_train = temporalize(X, y, timesteps)\n",
    "    history = model_lstm.fit(X_train, y_train, epochs=100, batch_size=4)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def treinar_lstm_ac_2(X,y, timesteps, num_classes, model_lstm):\n",
    "    #TimeSeries to Supervised\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    print(y.shape)\n",
    "    print(X.shape)\n",
    "    for i in range(timesteps, len(X)):\n",
    "            X_train.append(X[i-timesteps : i])\n",
    "            y_train.append(y[i-timesteps : i])\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    #X_train = np.stack(X_train, axis=0)\n",
    "        \n",
    "    #Dimensão, número de linhas, número de colunas(timesteps) e número de features\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1], y_train.shape[2]))\n",
    "    #regressor.add(LSTM(units = 50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "   \n",
    "    #treinar\n",
    "    #validation_split = 0.3\n",
    "    history = model_lstm.fit(X_train, y_train, epochs=50, batch_size=4)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def get_lstm_model(num_classes, timesteps):\n",
    "    input_layer = Input(shape=(timesteps, num_classes), name='input', dtype='float32')\n",
    "    #x = Conv1D(filters=256, kernel_size=4, activation='relu', input_shape=(timesteps,num_classes))(input_layer)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    #x = MaxPooling1D(pool_size=3)(x)\n",
    "    #x = Flatten()(x)\n",
    "    #x = Dense(100, activation='relu')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(75, input_shape = (timesteps, num_classes), return_sequences=True),name='bilstm')(input_layer)\n",
    "    x = layers.Bidirectional(layers.LSTM(50, input_shape = (timesteps, num_classes)),name='bilstm2')(x)\n",
    "    #x = layers.LSTM(120, input_shape = (timesteps, num_classes))(input_layer)\n",
    "    #x = Dense(12, activation='relu')(x)\n",
    "    #Criar Output Layer\n",
    "    output = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model_lstm = Model(input_layer, output)\n",
    "    #compilar\n",
    "    model_lstm.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "    \n",
    "    model_lstm.summary()\n",
    "    return model_lstm\n",
    "\n",
    "def data_to_timesteps(X):\n",
    "    X_train = []\n",
    "    for i in range(timesteps, len(X)):\n",
    "            X_train.append(X[i-timesteps : i])\n",
    "            \n",
    "    X_train = np.array(X_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    return X_train\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "def treinar_lstm(X,y, timesteps, num_classes, model_lstm):\n",
    "    #TimeSeries to Supervised\n",
    "    X_train = []\n",
    "    y_train = y\n",
    "    \n",
    "    for i in range(timesteps, len(X)):\n",
    "            X_train.append(X[i-timesteps : i])\n",
    "            \n",
    "    X_train = np.array(X_train)\n",
    "    \n",
    "    #X_train = np.stack(X_train, axis=0)\n",
    "        \n",
    "    #Dimensão, número de linhas, número de colunas(timesteps) e número de features\n",
    "    print(X_train.shape)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    #regressor.add(LSTM(units = 50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "   \n",
    "    #treinar\n",
    "    #validation_split = 0.3\n",
    "    history = model_lstm.fit(X_train, y_train, epochs=150, batch_size=4)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def to_one_hot_ts(y, class_mapping, num_classes, timesteps):\n",
    "    y_int = y.map(class_mapping)\n",
    "    y_int = y_int[timesteps:]\n",
    "    \n",
    "    return to_categorical(y_int, num_classes)\n",
    "\n",
    "def decode_timeseries(y_pred):\n",
    "    y_decoded = []\n",
    "    cont = 1\n",
    "    len_y_true = len(y_pred) + timesteps - 1\n",
    "    for i in range(len(y_pred) + timesteps - 1):\n",
    "        if i < len(y_pred):\n",
    "            y_decoded.append(np.argmax(y_pred[i][0]))\n",
    "        else:\n",
    "            y_decoded.append(np.argmax(y_pred[-1][cont]))\n",
    "            cont += 1\n",
    "            \n",
    "    return y_decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2eRCDGNVdCI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bad results\n",
    "timesteps = 5\n",
    "model_lstm = get_lstm_model(num_classes, timesteps)\n",
    "y_train_lf = []\n",
    "X_lf_pp_train = []\n",
    "y_true_train_docs = []\n",
    "for i in X_keys[:train_size]:\n",
    "    docs[i]['sent_text_t1'] = docs[i]['sent_text'].shift(-1)\n",
    "    docs[i].dropna(inplace = True)\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    \n",
    "    y = to_one_hot_ts(docs[i]['sent_text_t1'], class_mapping, num_classes, timesteps)\n",
    "    X_train_image = image_to_numpy(X_image)\n",
    "    training_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    training_data.load_data()\n",
    "\n",
    "\n",
    "    X_train_text = training_data.get_data_3dim()\n",
    "\n",
    "    \n",
    "    X_lf = model_hybrid.predict([X_train_text, X_train_image])\n",
    "    X_lf_pp = np.eye(X_lf.shape[1])[X_lf.argmax(1)]\n",
    "    \n",
    "    y_true_train_docs.append(y)\n",
    "    X_lf_pp_train.append(data_to_timesteps(X_lf_pp))\n",
    "\n",
    "\n",
    "    history = treinar_lstm(X_lf_pp, y, timesteps, num_classes, model_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmmWXgf7VdCJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y61aDL3hVdCJ"
   },
   "outputs": [],
   "source": [
    "y_true_train = []\n",
    "y_pred_train = []\n",
    "for i in range(len(y_true_train_docs)):\n",
    "    y_true_train.extend(y_true_train_docs[i])\n",
    "    y_pred = model_lstm.predict(X_lf_pp_train[i])\n",
    "    y_pred_train.extend(y_pred)\n",
    "\n",
    "print(np.array(y_true_train).shape)\n",
    "print(np.array(y_pred_train).shape)   \n",
    "print(one_hot_decode(y_true_train))\n",
    "print(one_hot_decode(y_pred_train))\n",
    "print(classification_report(one_hot_decode(y_true_train), one_hot_decode(y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bsq4gyMCVdCK"
   },
   "outputs": [],
   "source": [
    "X_lf_pp_test = []\n",
    "y_true_test_docs = []\n",
    "for i in X_keys[train_size:]:\n",
    "    docs[i]['sent_text_t1'] = docs[i]['sent_text'].shift(-1)\n",
    "    docs[i].dropna(inplace = True)\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot_ts(docs[i]['sent_text_t1'], class_mapping, num_classes, timesteps)\n",
    "    \n",
    "    X_test_image = image_to_numpy(X_image)\n",
    "    test_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    test_data.load_data()\n",
    "\n",
    "    X_test_text = test_data.get_data_3dim()\n",
    "    X_lf_test = model_hybrid.predict([X_test_text, X_test_image])\n",
    "    X_lf_test_pp = np.eye(X_lf_test.shape[1])[X_lf_test.argmax(1)]\n",
    "    \n",
    "    y_true_test_docs.append(y)\n",
    "    X_lf_pp_test.append(data_to_timesteps(X_lf_test_pp))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaMGGfKJVdCK"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "for i in range(len(y_true_test_docs)):\n",
    "    y_true_test.extend(y_true_test_docs[i])\n",
    "    y_pred = model_lstm.predict(X_lf_pp_test[i])\n",
    "    y_pred_test.extend(y_pred)\n",
    "\n",
    "print(np.array(y_true_test).shape)\n",
    "print(np.array(y_pred_test).shape)                   \n",
    "print(classification_report(one_hot_decode(y_true_test), one_hot_decode(y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8a5W_7xVdCK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xeQViD0lVdCK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L32yXseJVdCL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGXabe7GVdCL"
   },
   "source": [
    "## SEQ TO SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MKCABwNVdCL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timesteps = 3\n",
    "model_lstm = get_lstm_model_with_attention(num_classes, timesteps)\n",
    "y_train_lf = []\n",
    "X_lf_pp_train = []\n",
    "y_true_train_docs = []\n",
    "for i in X_keys[:train_size]:\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot_ts(docs[i]['sent_text'], class_mapping, num_classes, timesteps)\n",
    "    \n",
    "    X_train_image = image_to_numpy(X_image)\n",
    "    training_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    training_data.load_data()\n",
    "\n",
    "\n",
    "    X_train_text = training_data.get_data_3dim()\n",
    "\n",
    "    \n",
    "    X_lf = model_hybrid.predict([X_train_text, X_train_image])\n",
    "    X_lf_pp = np.eye(X_lf.shape[1])[X_lf.argmax(1)]\n",
    "    \n",
    "    y_true_train_docs.append(data_to_timesteps(y))\n",
    "    X_lf_pp_train.append(data_to_timesteps(X_lf_pp))\n",
    "    history = treinar_lstm_ac_2(X_lf_pp, y, timesteps, num_classes, model_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KshVhrPSVdCL"
   },
   "outputs": [],
   "source": [
    "y_true_train = []\n",
    "y_pred_train = []\n",
    "for i in range(len(y_true_train_docs)):\n",
    "    y_true_train.extend(decode_timeseries(y_true_train_docs[i]))\n",
    "    y_pred = model_lstm.predict(X_lf_pp_train[i])\n",
    "    y_pred_train.extend(decode_timeseries(y_pred))\n",
    "\n",
    "print(y_true_train)\n",
    "print(y_pred_train)                   \n",
    "print(classification_report(y_true_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdY-JdOzVdCL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_lf_pp_test = []\n",
    "y_true_test_docs = []\n",
    "for i in X_keys[train_size:]:\n",
    "    X_image = docs[i]['image_path'].apply(get_array)\n",
    "    X_text = docs[i]['text']\n",
    "    y = to_one_hot_ts(docs[i]['sent_text'], class_mapping, num_classes, timesteps)\n",
    "    \n",
    "    X_test_image = image_to_numpy(X_image)\n",
    "    test_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "    test_data.load_data()\n",
    "\n",
    "    X_test_text = test_data.get_data_3dim()\n",
    "    X_lf_test = model_hybrid.predict([X_test_text, X_test_image])\n",
    "    X_lf_test_pp = np.eye(X_lf_test.shape[1])[X_lf_test.argmax(1)]\n",
    "    \n",
    "    y_true_test_docs.append(data_to_timesteps(y))\n",
    "    X_lf_pp_test.append(data_to_timesteps(X_lf_test_pp))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-891lNvYVdCL"
   },
   "outputs": [],
   "source": [
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "for i in range(len(y_true_test_docs)):\n",
    "    y_true_test.extend(decode_timeseries(y_true_test_docs[i]))\n",
    "    y_pred = model_lstm.predict(X_lf_pp_test[i])\n",
    "    y_pred_test.extend(decode_timeseries(y_pred))\n",
    "\n",
    "print(y_true_test)\n",
    "print(y_pred_test)                   \n",
    "print(classification_report(y_true_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yateACcGVdCM",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuuDhoc_VdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bmS88ZQVdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oeW5NEFVdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3ycaj0IVdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRPLNUKjVdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nXc-LO-VdCM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pglp0YviVdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFKRqVI3VdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKUgr88-VdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cp_wQ_QcVdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ReftgEDzVdCN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trQTdX0cVdCN"
   },
   "outputs": [],
   "source": [
    "print(X_train_text.shape)\n",
    "print(X_test_text.shape)\n",
    "print(X_train_image.shape)\n",
    "print(X_test_image.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X_text = np.concatenate((X_train_text, X_test_text))\n",
    "X_image = np.concatenate((X_train_image, X_test_image))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "\n",
    "print(X_text.shape)\n",
    "print(X_image.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMPoSOWIVdCN"
   },
   "outputs": [],
   "source": [
    "X_image = df['image_path'].apply(get_array)\n",
    "X_text = df['text']\n",
    "y = to_one_hot(df['sent_text'], class_mapping, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmZ3v32NVdCN"
   },
   "outputs": [],
   "source": [
    "text_data = Data(data_source=X_text,\n",
    "                         alphabet=data_config[\"data\"][\"alphabet\"],\n",
    "                         input_size=data_config[\"data\"][\"input_size\"],\n",
    "                         num_of_classes=data_config[\"data\"][\"num_of_classes\"],\n",
    "                         alphabet_size=data_config[\"data\"][\"alphabet_size\"])\n",
    "text_data.load_data()\n",
    "X_text_array = text_data.get_data_3dim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNBu5Gb7VdCN"
   },
   "outputs": [],
   "source": [
    "def image_to_numpy(image_df):\n",
    "    all_images = []\n",
    "    for i in range(len(image_df)):\n",
    "        all_images.append(image_df.iloc[i])  \n",
    "    return np.array(all_images)\n",
    "\n",
    "X_image_array = image_to_numpy(X_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbaUkes3VdCO"
   },
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGNHWy5XVdCO"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_hybrid = load_model('model_ness_txt_image_v1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTsV1ap6VdCO"
   },
   "outputs": [],
   "source": [
    "layer_name = 'concatanated'\n",
    "  \n",
    "layer_output = model_hybrid.get_layer(layer_name).output\n",
    "\n",
    "intermediate_model = Model(inputs=model_hybrid.input,outputs=layer_output)\n",
    "\n",
    "encoded_page = intermediate_model.predict([X_text_array, X_image_array])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgdUE8_-VdCO"
   },
   "outputs": [],
   "source": [
    "print(type(encoded_page))\n",
    "print(encoded_page.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CI6QOk2PVdCO"
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['encoded_page'] = []\n",
    "for i in encoded_page:\n",
    "    data['encoded_page'].append(i)\n",
    "    \n",
    "df_encoded = pd.DataFrame.from_dict(data)\n",
    "df = pd.concat([df, df_encoded], axis=1, sort=False)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfcjPzSTVdCO"
   },
   "outputs": [],
   "source": [
    "X_encoded = df['encoded_page']\n",
    "y = to_one_hot(df['sent_text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "X_test = np.stack(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ykt9TgD1VdCO"
   },
   "outputs": [],
   "source": [
    "encoded_input =Input(shape=(512,), name='encoded_page', dtype='float32')\n",
    "#x = Dense(1024, activation='relu')(encoded_page)\n",
    "output = Dense(num_classes, activation='softmax', name='output')(encoded_input)\n",
    "model = Model(encoded_input, output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIffiU-0VdCP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=400, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz-nN8rXVdCP"
   },
   "outputs": [],
   "source": [
    "#X = df[['encoded_page','image_page', 'image_name', 'sent_text']]\n",
    "X = df[['encoded_page', 'image_name', 'sent_text']]\n",
    "#X['sent_text_one_hot'] = to_one_hot(X['sent_text'])\n",
    "docs = {}\n",
    "\n",
    "values = X['image_name'].value_counts()\n",
    "print(values.index)\n",
    "print(values['12'])\n",
    "\n",
    "for i in values.index:\n",
    "    docs[i] = X[X['image_name'] == i].sort_values(by=['image_name']).drop(['image_name'], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SkU7it2VdCP"
   },
   "outputs": [],
   "source": [
    "def treinar_lstm(X,y, timesteps):\n",
    "    #TimeSeries to Supervised\n",
    "    X_train = []\n",
    "    y_train = y\n",
    "    \n",
    "    for i in range(timesteps, len(X)):\n",
    "            X_train.append(X[i-timesteps : i])\n",
    "            \n",
    "    X_train = np.array(X_train)\n",
    "    \n",
    "    #X_train = np.stack(X_train, axis=0)\n",
    "        \n",
    "    #Dimensão, número de linhas, número de colunas(timesteps) e número de features\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    #print(X_train.shape)\n",
    "    #print(y_train.shape)\n",
    "\n",
    "    #regressor.add(LSTM(units = 50, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]), name='input', dtype='float32')\n",
    "    x = layers.Bidirectional(layers.LSTM(512, input_shape = (X_train.shape[1], X_train.shape[2])), name='bilstm')(input_layer)\n",
    "    #x = layers.LSTM(50, input_shape = (X_train.shape[1], X_train.shape[2]))(input_layer)\n",
    "    #Criar Output Layer\n",
    "    output = Dense(8, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model_lstm = Model(input_layer, output)\n",
    "    #compilar\n",
    "    model_lstm.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "    \n",
    "    model_lstm.summary()\n",
    "    #treinar\n",
    "    history = model_lstm.fit(X_train, y_train, epochs=150, batch_size=32, validation_split = 0.3)\n",
    "    \n",
    "    return model_lstm, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oBsM5_MVdCP"
   },
   "outputs": [],
   "source": [
    "def to_one_hot_ts(y, timesteps):\n",
    "    num_classes = y.nunique()\n",
    "    class_mapping = {label:idx for idx,label in enumerate(np.unique(y))}\n",
    "    y_int = y.map(class_mapping)\n",
    "    y_int = y_int[timesteps:]\n",
    "    \n",
    "    return to_categorical(y_int, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdMwR4qrVdCP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_test = docs['12'].drop(['sent_text', 'image_page], axis=1)\n",
    "df_test = docs['12'].drop(['sent_text'], axis=1)\n",
    "\n",
    "X_test = df_test['encoded_page']\n",
    "\n",
    "y_test = to_one_hot(docs['12']['sent_text'])\n",
    "timesteps = 5\n",
    "\n",
    "regressor, history = treinar_lstm(X_test,y_test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtICv_BJVdCP"
   },
   "outputs": [],
   "source": [
    "X_test = df_test['encoded_page'][5:]\n",
    "y_test = to_one_hot(docs['12']['sent_text'])\n",
    "\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "\n",
    "encoded_input =Input(shape=(512,), name='encoded_page', dtype='float32')\n",
    "#x = Dense(1024, activation='relu')(encoded_page)\n",
    "output = Dense(8, activation='softmax', name='output')(encoded_input)\n",
    "model = Model(encoded_input, output)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    metrics=['acc'])\n",
    "model.fit(X_test, y_test, epochs=1000, batch_size=32, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtDIMFyIVdCP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "0-2-multi-input-nn-hmm-30-mar-2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "keras-tf-gpu",
   "language": "python",
   "name": "keras-tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
